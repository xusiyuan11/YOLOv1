"""
SwinYOLOè®­ç»ƒè„šæœ¬
ç®€åŒ–çš„è®­ç»ƒæµç¨‹ï¼Œä¸“æ³¨äºSwin Transformer + YOLOæ£€æµ‹
"""

import torch
import torch.optim as optim
from torch.utils.data import DataLoader
import os
import time
from tqdm import tqdm
import json
import numpy as np

from SwinYOLO import create_swin_yolo
from dataset import VOC_Detection_Set  # ä½¿ç”¨ç°æœ‰çš„æ•°æ®é›†
from evaluation import evaluate_model, decode_predictions, apply_nms_to_detections
from visualization import (plot_training_curves, plot_loss_components, plot_map_curves, 
                          create_training_summary_plot, plot_class_wise_performance)


def custom_collate_fn(batch):
    """è‡ªå®šä¹‰çš„collateå‡½æ•°ï¼Œæ­£ç¡®å¤„ç†[gt, mask_pos, mask_neg]æ ¼å¼çš„targets"""
    images = []
    targets = []
    
    for sample in batch:
        img, target_data = sample
        images.append(img)
        
        # æ£€æŸ¥target_dataçš„ç±»å‹
        if isinstance(target_data, list) and len(target_data) == 3:
            # çœŸå®æ•°æ®é›†æ ¼å¼: [gt, mask_pos, mask_neg]
            targets.append(target_data)
        elif isinstance(target_data, torch.Tensor):
            # è™šæ‹Ÿæ•°æ®é›†æ ¼å¼: ç›´æ¥æ˜¯ä¸€ä¸ªå¼ é‡
            # å°†å…¶è½¬æ¢ä¸ºå…¼å®¹æ ¼å¼
            targets.append(target_data)
        else:
            targets.append(target_data)
    
    # å°†å›¾åƒå †å ä¸ºæ‰¹å¤„ç†å¼ é‡
    images = torch.stack(images)
    
    return images, targets


class SwinYOLOTrainer:
    """SwinYOLOè®­ç»ƒå™¨"""
    
    def __init__(self, 
                 num_classes=20,
                 input_size=448,
                 grid_size=7,
                 device='cuda',
                 save_dir='./checkpoints/swin_yolo'):
        
        self.num_classes = num_classes
        self.input_size = input_size
        self.grid_size = grid_size
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.save_dir = save_dir
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        
        # åˆ›å»ºæ¨¡å‹å’ŒæŸå¤±å‡½æ•°
        self.model, self.loss_fn = create_swin_yolo(
            num_classes=num_classes,
            input_size=input_size,
            grid_size=grid_size
        )
        self.model.to(self.device)
        self.loss_fn.to(self.device)
        
        # è®­ç»ƒç»Ÿè®¡
        self.train_losses = []
        self.val_losses = []
        self.learning_rates = []
        
        # è¯¦ç»†æŸå¤±è®°å½•
        self.train_losses_detailed = {
            'total_loss': [],
            'coord_loss': [],
            'conf_loss': [],
            'class_loss': []
        }
        self.val_losses_detailed = {
            'total_loss': [],
            'coord_loss': [],
            'conf_loss': [],
            'class_loss': []
        }
        
        # mAPè®°å½•
        self.map_history = []
        self.map_epochs = []
        
        # mAPè®¡ç®—ä¼˜åŒ–é…ç½® (åº”ç”¨YOLOv1/v3ä¼˜åŒ–ç»éªŒ)
        self.map_calculation_config = {
            'calculate_interval': 2,  # æ¯2ä¸ªepochè®¡ç®—ä¸€æ¬¡mAP
            'fast_mode': True,        # ä½¿ç”¨å¿«é€ŸmAPè®¡ç®—
            'sample_ratio': 0.3,      # åªç”¨30%çš„éªŒè¯é›†è®¡ç®—mAP
            'confidence_threshold': 0.2,  # SwinYOLOé€‚åˆçš„ç½®ä¿¡åº¦é˜ˆå€¼
            'max_detections': 100,    # é™åˆ¶æ¯å¼ å›¾çš„æœ€å¤§æ£€æµ‹æ•°
        }
        
        print(f"âœ… SwinYOLOè®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   è®¾å¤‡: {self.device}")
        print(f"   mAPè®¡ç®—ä¼˜åŒ–: é—´éš”{self.map_calculation_config['calculate_interval']}è½®, å¿«é€Ÿæ¨¡å¼å¯ç”¨")
        print(f"   æ¨¡å‹å‚æ•°: {sum(p.numel() for p in self.model.parameters()):,}")
        print(f"   ä¿å­˜ç›®å½•: {self.save_dir}")
    
    def configure_map_calculation(self, calculate_interval=None, fast_mode=None, 
                                 sample_ratio=None, confidence_threshold=None, max_detections=None):
        """åŠ¨æ€é…ç½®mAPè®¡ç®—å‚æ•° (åº”ç”¨YOLOv1/v3ä¼˜åŒ–ç»éªŒ)"""
        if calculate_interval is not None:
            self.map_calculation_config['calculate_interval'] = calculate_interval
        if fast_mode is not None:
            self.map_calculation_config['fast_mode'] = fast_mode
        if sample_ratio is not None:
            self.map_calculation_config['sample_ratio'] = sample_ratio
        if confidence_threshold is not None:
            self.map_calculation_config['confidence_threshold'] = confidence_threshold
        if max_detections is not None:
            self.map_calculation_config['max_detections'] = max_detections
            
        print(f"ğŸ”§ SwinYOLO mAPè®¡ç®—é…ç½®å·²æ›´æ–°:")
        for key, value in self.map_calculation_config.items():
            print(f"  {key}: {value}")
    
    def create_optimizer(self, base_lr=0.001, backbone_lr_ratio=0.1, weight_decay=0.0005):
        """åˆ›å»ºä¼˜åŒ–å™¨ï¼Œä½¿ç”¨ä¸åŒçš„å­¦ä¹ ç‡"""
        param_groups = self.model.get_parameter_groups(base_lr, backbone_lr_ratio)
        
        optimizer = optim.Adam([
            {'params': group['params'], 'lr': group['lr']} 
            for group in param_groups
        ], weight_decay=weight_decay)
        
        return optimizer
    
    def create_scheduler(self, optimizer, epochs):
        """åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        scheduler = optim.lr_scheduler.CosineAnnealingLR(
            optimizer, 
            T_max=epochs,
            eta_min=1e-6
        )
        return scheduler
    
    def train_epoch(self, train_loader, optimizer, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0.0
        total_coord_loss = 0.0
        total_conf_loss = 0.0
        total_class_loss = 0.0
        
        progress_bar = tqdm(train_loader, desc=f'è®­ç»ƒ Epoch {epoch+1}')
        
        for batch_idx, (images, targets) in enumerate(progress_bar):
            images = images.to(self.device)
            
            # å¤„ç†targetsï¼šæ”¯æŒä¸¤ç§æ ¼å¼
            if isinstance(targets, list) and len(targets) > 0:
                # æ£€æŸ¥ç¬¬ä¸€ä¸ªtargetçš„æ ¼å¼æ¥ç¡®å®šæ•°æ®ç±»å‹
                first_target = targets[0]
                
                if isinstance(first_target, list) and len(first_target) == 3:
                    # çœŸå®æ•°æ®é›†æ ¼å¼: [gt, mask_pos, mask_neg]
                    batch_gt = []
                    batch_mask_pos = []
                    batch_mask_neg = []
                    
                    for target in targets:
                        gt, mask_pos, mask_neg = target
                        # ç¡®ä¿gtæ˜¯tensor
                        if isinstance(gt, np.ndarray):
                            gt = torch.from_numpy(gt).float()
                        batch_gt.append(gt)
                        batch_mask_pos.append(mask_pos)
                        batch_mask_neg.append(mask_neg)
                    
                    # å †å ä¸ºæ‰¹å¤„ç†å¼ é‡
                    targets = [
                        torch.stack(batch_gt),
                        torch.stack(batch_mask_pos), 
                        torch.stack(batch_mask_neg)
                    ]
                    
                elif isinstance(first_target, torch.Tensor):
                    # è™šæ‹Ÿæ•°æ®é›†æ ¼å¼: ç›´æ¥æ˜¯å¼ é‡
                    targets = torch.stack(targets)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„targetæ ¼å¼: {type(first_target)}")
            
            # å°†targetsç§»åŠ¨åˆ°è®¾å¤‡
            if isinstance(targets, list):
                targets = [t.to(self.device) for t in targets]
            else:
                targets = targets.to(self.device)
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            predictions = self.model(images)
            
            # è®¡ç®—æŸå¤±
            # targetsç°åœ¨æ˜¯[batch_gt, batch_mask_pos, batch_mask_neg]çš„åˆ—è¡¨
            if isinstance(targets, list) and len(targets) >= 1:
                # ä½¿ç”¨gtä½œä¸ºä¸»è¦ç›®æ ‡ï¼Œmaskç”¨äºå…¶ä»–ç›®çš„
                gt_targets = targets[0]  # batch_gt
                loss_dict = self.loss_fn(predictions, gt_targets)
            else:
                loss_dict = self.loss_fn(predictions, targets)
            loss = loss_dict['total_loss']
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            total_coord_loss += loss_dict['coord_loss'].item()
            total_conf_loss += loss_dict['conf_loss'].item()
            total_class_loss += loss_dict['class_loss'].item()
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Coord': f'{loss_dict["coord_loss"].item():.4f}',
                'Conf': f'{loss_dict["conf_loss"].item():.4f}',
                'Class': f'{loss_dict["class_loss"].item():.4f}'
            })
        
        avg_loss = total_loss / len(train_loader)
        avg_coord_loss = total_coord_loss / len(train_loader)
        avg_conf_loss = total_conf_loss / len(train_loader)
        avg_class_loss = total_class_loss / len(train_loader)
        
        return {
            'total_loss': avg_loss,
            'coord_loss': avg_coord_loss,
            'conf_loss': avg_conf_loss,
            'class_loss': avg_class_loss
        }
    
    def validate_epoch(self, val_loader, epoch):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        total_loss = 0.0
        total_coord_loss = 0.0
        total_conf_loss = 0.0
        total_class_loss = 0.0
        
        with torch.no_grad():
            progress_bar = tqdm(val_loader, desc=f'éªŒè¯ Epoch {epoch+1}')
            
            for images, targets in progress_bar:
                images = images.to(self.device)
                
                # å¤„ç†targetsï¼šæ”¯æŒä¸¤ç§æ ¼å¼
                if isinstance(targets, list) and len(targets) > 0:
                    # æ£€æŸ¥ç¬¬ä¸€ä¸ªtargetçš„æ ¼å¼æ¥ç¡®å®šæ•°æ®ç±»å‹
                    first_target = targets[0]
                    
                    if isinstance(first_target, list) and len(first_target) == 3:
                        # çœŸå®æ•°æ®é›†æ ¼å¼: [gt, mask_pos, mask_neg]
                        batch_gt = []
                        batch_mask_pos = []
                        batch_mask_neg = []
                        
                        for target in targets:
                            gt, mask_pos, mask_neg = target
                            # ç¡®ä¿gtæ˜¯tensor
                            if isinstance(gt, np.ndarray):
                                gt = torch.from_numpy(gt).float()
                            batch_gt.append(gt)
                            batch_mask_pos.append(mask_pos)
                            batch_mask_neg.append(mask_neg)
                        
                        # å †å ä¸ºæ‰¹å¤„ç†å¼ é‡
                        targets = [
                            torch.stack(batch_gt),
                            torch.stack(batch_mask_pos), 
                            torch.stack(batch_mask_neg)
                        ]
                        
                    elif isinstance(first_target, torch.Tensor):
                        # è™šæ‹Ÿæ•°æ®é›†æ ¼å¼: ç›´æ¥æ˜¯å¼ é‡
                        targets = torch.stack(targets)
                    else:
                        raise ValueError(f"ä¸æ”¯æŒçš„targetæ ¼å¼: {type(first_target)}")
                
                # å°†targetsç§»åŠ¨åˆ°è®¾å¤‡
                if isinstance(targets, list):
                    targets = [t.to(self.device) for t in targets]
                else:
                    targets = targets.to(self.device)
                
                predictions = self.model(images)
                
                # è®¡ç®—æŸå¤±
                if isinstance(targets, list) and len(targets) >= 1:
                    # ä½¿ç”¨gtä½œä¸ºä¸»è¦ç›®æ ‡
                    gt_targets = targets[0]  # batch_gt
                    loss_dict = self.loss_fn(predictions, gt_targets)
                else:
                    loss_dict = self.loss_fn(predictions, targets)
                
                total_loss += loss_dict['total_loss'].item()
                total_coord_loss += loss_dict['coord_loss'].item()
                total_conf_loss += loss_dict['conf_loss'].item()
                total_class_loss += loss_dict['class_loss'].item()
                
                progress_bar.set_postfix({
                    'Val Loss': f'{loss_dict["total_loss"].item():.4f}'
                })
        
        avg_loss = total_loss / len(val_loader)
        avg_coord_loss = total_coord_loss / len(val_loader)
        avg_conf_loss = total_conf_loss / len(val_loader)
        avg_class_loss = total_class_loss / len(val_loader)
        
        return {
            'total_loss': avg_loss,
            'coord_loss': avg_coord_loss,
            'conf_loss': avg_conf_loss,
            'class_loss': avg_class_loss
        }
    
    def evaluate_map(self, val_loader, conf_threshold=0.1, iou_threshold=0.5):
        """è¯„ä¼°æ¨¡å‹çš„mAPæŒ‡æ ‡"""
        print("ğŸ“Š å¼€å§‹è¯„ä¼°mAP...")
        
        map_results = evaluate_model(
            model=self.model,
            dataloader=val_loader,
            device=self.device,
            num_classes=self.num_classes,
            conf_threshold=conf_threshold,
            iou_threshold=iou_threshold
        )
        
        print(f"âœ… mAPè¯„ä¼°å®Œæˆ:")
        print(f"   mAP@0.5: {map_results['mAP']:.4f}")
        
        # æ˜¾ç¤ºå‰5ä¸ªç±»åˆ«çš„AP
        class_aps = [(k, v) for k, v in map_results.items() if k.startswith('class_')]
        class_aps.sort(key=lambda x: x[1], reverse=True)
        
        print("   ç±»åˆ«APåˆ†å¸ƒ:")
        # æ˜¾ç¤ºæ‰€æœ‰ç±»åˆ«çš„APå€¼ï¼Œä¾¿äºè°ƒè¯•
        non_zero_aps = [(k, v) for k, v in class_aps if v > 0.001]
        zero_aps = [(k, v) for k, v in class_aps if v <= 0.001]
        
        print(f"     æœ‰æ•ˆç±»åˆ«æ•°: {len(non_zero_aps)}/{len(class_aps)}")
        print("     Top 5 ç±»åˆ«AP:")
        for i, (class_name, ap) in enumerate(class_aps[:5]):
            class_id = int(class_name.split('_')[1])
            class_name_str = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',
                             'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor'][class_id]
            print(f"     ç±»åˆ«{class_id}({class_name_str}): {ap:.4f}")
        
        if len(zero_aps) > 15:  # å¦‚æœè¶…è¿‡15ä¸ªç±»åˆ«APä¸º0
            print(f"     âš ï¸  è­¦å‘Š: {len(zero_aps)}ä¸ªç±»åˆ«çš„APä¸º0ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜!")
            print(f"     å»ºè®®æ£€æŸ¥: æ•°æ®åˆ†å¸ƒã€æ¨¡å‹é¢„æµ‹ã€ç±»åˆ«æ˜ å°„")
        
        return map_results
    
    def evaluate_map_fast(self, val_loader, conf_threshold=0.1, iou_threshold=0.5, max_batches=10):
        """
        å¿«é€ŸmAPè¯„ä¼° - åªè¯„ä¼°å‰å‡ ä¸ªbatchï¼Œç”¨äºè®­ç»ƒåˆæœŸå¿«é€Ÿåé¦ˆ
        
        Args:
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            iou_threshold: IoUé˜ˆå€¼  
            max_batches: æœ€å¤§è¯„ä¼°batchæ•°
        """
        print(f"ğŸ“Š å¿«é€ŸmAPè¯„ä¼° (ä»…å‰{max_batches}ä¸ªbatch)...")
        
        # åˆ›å»ºä¸€ä¸ªé™åˆ¶batchæ•°é‡çš„å­é›†
        from itertools import islice
        limited_loader = islice(val_loader, max_batches)
        
        # ä½¿ç”¨ç°æœ‰çš„è¯„ä¼°å‡½æ•°ï¼Œä½†åªå¤„ç†æœ‰é™çš„æ•°æ®
        map_results = evaluate_model(
            model=self.model,
            dataloader=limited_loader,
            device=self.device,
            num_classes=self.num_classes,
            conf_threshold=conf_threshold,
            iou_threshold=iou_threshold
        )
        
        print(f"âœ… å¿«é€ŸmAPè¯„ä¼°å®Œæˆ (åŸºäº{max_batches}ä¸ªbatch):")
        print(f"   mAP@0.5: {map_results['mAP']:.4f}")
        
        return map_results
    
    def plot_real_time_results(self, current_epoch):
        """ç»˜åˆ¶å®æ—¶è®­ç»ƒç»“æœ"""
        print(f"ğŸ“Š ç”ŸæˆEpoch {current_epoch}çš„è®­ç»ƒå›¾è¡¨...")
        
        vis_dir = os.path.join(self.save_dir, 'visualizations')
        os.makedirs(vis_dir, exist_ok=True)
        
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        if len(self.train_losses) > 1:
            train_curve_path = os.path.join(vis_dir, f'training_curves_epoch_{current_epoch}.png')
            plot_training_curves(
                self.train_losses, 
                self.val_losses,
                self.learning_rates if self.learning_rates else None,
                save_path=train_curve_path,
                title=f"SwinYOLOè®­ç»ƒæ›²çº¿ (Epoch {current_epoch})"
            )
        
        # ç»˜åˆ¶æŸå¤±ç»„ä»¶
        if len(self.train_losses_detailed['total_loss']) > 1:
            components_path = os.path.join(vis_dir, f'loss_components_epoch_{current_epoch}.png')
            plot_loss_components(
                self.train_losses_detailed,
                self.val_losses_detailed,
                save_path=components_path,
                title=f"SwinYOLOæŸå¤±ç»„ä»¶ (Epoch {current_epoch})"
            )
        
        # ç»˜åˆ¶mAPæ›²çº¿
        if len(self.map_history) > 1:
            map_path = os.path.join(vis_dir, f'map_curves_epoch_{current_epoch}.png')
            plot_map_curves(
                self.map_history,
                save_path=map_path,
                title=f"SwinYOLO mAPæ›²çº¿ (Epoch {current_epoch})"
            )
            
            # æœ€æ–°çš„ç±»åˆ«æ€§èƒ½åˆ†æ
            latest_map = self.map_history[-1]
            class_perf_path = os.path.join(vis_dir, f'class_performance_epoch_{current_epoch}.png')
            plot_class_wise_performance(
                latest_map,
                save_path=class_perf_path,
                title=f"å„ç±»åˆ«æ€§èƒ½åˆ†æ (Epoch {current_epoch})"
            )
    
    def create_final_visualization(self):
        """åˆ›å»ºè®­ç»ƒå®Œæˆåçš„å®Œæ•´å¯è§†åŒ–"""
        print("ğŸ¨ åˆ›å»ºæœ€ç»ˆè®­ç»ƒå¯è§†åŒ–...")
        
        vis_dir = os.path.join(self.save_dir, 'final_results')
        os.makedirs(vis_dir, exist_ok=True)
        
        # æœ€ç»ˆè®­ç»ƒæ›²çº¿
        final_train_path = os.path.join(vis_dir, 'final_training_curves.png')
        plot_training_curves(
            self.train_losses, 
            self.val_losses,
            self.learning_rates if self.learning_rates else None,
            save_path=final_train_path,
            title="SwinYOLOæœ€ç»ˆè®­ç»ƒæ›²çº¿"
        )
        
        # æœ€ç»ˆæŸå¤±ç»„ä»¶
        final_components_path = os.path.join(vis_dir, 'final_loss_components.png')
        plot_loss_components(
            self.train_losses_detailed,
            self.val_losses_detailed,
            save_path=final_components_path,
            title="SwinYOLOæœ€ç»ˆæŸå¤±ç»„ä»¶"
        )
        
        # æœ€ç»ˆmAPæ›²çº¿
        if self.map_history:
            final_map_path = os.path.join(vis_dir, 'final_map_curves.png')
            plot_map_curves(
                self.map_history,
                save_path=final_map_path,
                title="SwinYOLOæœ€ç»ˆmAPæ›²çº¿"
            )
            
            # æœ€ç»ˆç±»åˆ«æ€§èƒ½
            final_class_path = os.path.join(vis_dir, 'final_class_performance.png')
            final_map = self.map_history[-1]
            plot_class_wise_performance(
                final_map,
                save_path=final_class_path,
                title="æœ€ç»ˆå„ç±»åˆ«æ€§èƒ½åˆ†æ"
            )
            
            print(f"ğŸ† æœ€ä½³mAP: {max(result['mAP'] for result in self.map_history):.4f}")
        
        return vis_dir
    
    def save_checkpoint(self, epoch, optimizer, scheduler, best_loss, is_best=False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
            'best_loss': best_loss,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'learning_rates': self.learning_rates,
            'config': {
                'num_classes': self.num_classes,
                'input_size': self.input_size,
                'grid_size': self.grid_size
            }
        }
        
        # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
        latest_path = os.path.join(self.save_dir, 'latest_checkpoint.pth')
        torch.save(checkpoint, latest_path)
        
        # ä¿å­˜æœ€ä½³æ£€æŸ¥ç‚¹
        if is_best:
            best_path = os.path.join(self.save_dir, 'best_checkpoint.pth')
            torch.save(checkpoint, best_path)
            print(f"âœ… æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {best_path}")
    
    def load_checkpoint(self, checkpoint_path, optimizer=None, scheduler=None):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint = torch.load(checkpoint_path, map_location=self.device, weights_only=False)
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        
        if optimizer and 'optimizer_state_dict' in checkpoint:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        if scheduler and 'scheduler_state_dict' in checkpoint:
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        self.train_losses = checkpoint.get('train_losses', [])
        self.val_losses = checkpoint.get('val_losses', [])
        self.learning_rates = checkpoint.get('learning_rates', [])
        
        return checkpoint['epoch'], checkpoint.get('best_loss', float('inf'))
    
    def train(self, 
              train_loader, 
              val_loader, 
              epochs=100,
              base_lr=0.001,
              backbone_lr_ratio=0.1,
              weight_decay=0.0005,
              resume_from=None,
              freeze_backbone_epochs=10):
        """
        è®­ç»ƒSwinYOLO
        
        Args:
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            epochs: è®­ç»ƒè½®æ•°
            base_lr: åŸºç¡€å­¦ä¹ ç‡
            backbone_lr_ratio: backboneå­¦ä¹ ç‡æ¯”ä¾‹
            weight_decay: æƒé‡è¡°å‡
            resume_from: æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„
            freeze_backbone_epochs: å†»ç»“backboneçš„è½®æ•°
        """
        print("="*60)
        print("ğŸš€ å¼€å§‹SwinYOLOè®­ç»ƒ")
        print("="*60)
        
        # åˆ›å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        optimizer = self.create_optimizer(base_lr, backbone_lr_ratio, weight_decay)
        scheduler = self.create_scheduler(optimizer, epochs)
        
        # æ¢å¤è®­ç»ƒ
        start_epoch = 0
        best_loss = float('inf')
        
        if resume_from and os.path.exists(resume_from):
            print(f"ğŸ“ ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {resume_from}")
            start_epoch, best_loss = self.load_checkpoint(resume_from, optimizer, scheduler)
        
        # å‰å‡ ä¸ªepochå†»ç»“backbone
        if start_epoch < freeze_backbone_epochs:
            self.model.freeze_backbone()
            print(f"ğŸ”’ å‰{freeze_backbone_epochs}ä¸ªepochå°†å†»ç»“Swin backbone")
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(start_epoch, epochs):
            # è§£å†»backbone
            if epoch == freeze_backbone_epochs:
                self.model.unfreeze_backbone()
                print(f"ğŸ”“ Epoch {epoch}: è§£å†»Swin backboneï¼Œå¼€å§‹ç«¯åˆ°ç«¯è®­ç»ƒ")
            
            # è®­ç»ƒ
            train_metrics = self.train_epoch(train_loader, optimizer, epoch)
            
            # éªŒè¯
            val_metrics = self.validate_epoch(val_loader, epoch)
            
            # æ›´æ–°å­¦ä¹ ç‡
            if scheduler:
                scheduler.step()
                current_lr = scheduler.get_last_lr()[0]
                self.learning_rates.append(current_lr)
            
            # è®°å½•æŸå¤±
            self.train_losses.append(train_metrics['total_loss'])
            self.val_losses.append(val_metrics['total_loss'])
            
            # è®°å½•è¯¦ç»†æŸå¤±
            for key in self.train_losses_detailed.keys():
                self.train_losses_detailed[key].append(train_metrics[key])
                self.val_losses_detailed[key].append(val_metrics[key])
            
            # æ‰“å°ç»“æœ
            print(f"Epoch {epoch+1}/{epochs}:")
            print(f"  è®­ç»ƒ - æ€»æŸå¤±: {train_metrics['total_loss']:.4f}, "
                  f"åæ ‡: {train_metrics['coord_loss']:.4f}, "
                  f"ç½®ä¿¡åº¦: {train_metrics['conf_loss']:.4f}, "
                  f"åˆ†ç±»: {train_metrics['class_loss']:.4f}")
            print(f"  éªŒè¯ - æ€»æŸå¤±: {val_metrics['total_loss']:.4f}, "
                  f"åæ ‡: {val_metrics['coord_loss']:.4f}, "
                  f"ç½®ä¿¡åº¦: {val_metrics['conf_loss']:.4f}, "
                  f"åˆ†ç±»: {val_metrics['class_loss']:.4f}")
            if scheduler:
                print(f"  å­¦ä¹ ç‡: {current_lr:.6f}")
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            is_best = val_metrics['total_loss'] < best_loss
            if is_best:
                best_loss = val_metrics['total_loss']
            
            # ğŸš€ ä¼˜åŒ–è¯„ä¼°é¢‘ç‡ - å‚è€ƒç°ä»£YOLOå®è·µ
            # å‰20è½®æ¯5è½®è¯„ä¼°ï¼Œä¸­æœŸæ¯3è½®è¯„ä¼°ï¼ŒåæœŸæ¯è½®è¯„ä¼°
            if epoch < 20:
                should_evaluate = (epoch + 1) % 5 == 0  # å‰20è½®ï¼šæ¯5è½®è¯„ä¼°
            elif epoch < 50:
                should_evaluate = (epoch + 1) % 3 == 0  # ä¸­æœŸï¼šæ¯3è½®è¯„ä¼°  
            else:
                should_evaluate = (epoch + 1) % 1 == 0  # åæœŸï¼šæ¯è½®è¯„ä¼°
            
            if should_evaluate:
                # è®­ç»ƒåˆæœŸä½¿ç”¨æ›´ä½çš„ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œéšç€è®­ç»ƒè¿›è¡Œé€æ¸æé«˜
                if epoch < 20:
                    conf_thresh = 0.01  # å‰20è½®ä½¿ç”¨å¾ˆä½çš„é˜ˆå€¼
                elif epoch < 50:
                    conf_thresh = 0.05  # ä¸­æœŸé€æ¸æé«˜
                else:
                    conf_thresh = 0.1   # åæœŸä½¿ç”¨æ ‡å‡†é˜ˆå€¼
                
                # ğŸš€ æ™ºèƒ½mAPè®¡ç®— (åº”ç”¨YOLOv1/v3ä¼˜åŒ–ç»éªŒ)
                start_time = time.time()
                
                if self.map_calculation_config['fast_mode']:
                    # å¿«é€Ÿæ¨¡å¼ï¼šä½¿ç”¨é‡‡æ ·æ¯”ä¾‹
                    sample_ratio = self.map_calculation_config['sample_ratio']
                    max_batches = max(1, int(len(val_loader) * sample_ratio))
                    map_results = self.evaluate_map_fast(
                        val_loader, 
                        conf_threshold=self.map_calculation_config['confidence_threshold'], 
                        max_batches=max_batches
                    )
                    print(f"  å¿«é€ŸmAPæ¨¡å¼: ä½¿ç”¨{max_batches}/{len(val_loader)}æ‰¹æ•°æ®")
                else:
                    # å®Œæ•´æ¨¡å¼
                    map_results = self.evaluate_map(
                        val_loader, 
                        conf_threshold=self.map_calculation_config['confidence_threshold'], 
                        iou_threshold=0.5
                    )
                
                map_time = time.time() - start_time
                print(f"  â±ï¸ mAPè®¡ç®—è€—æ—¶: {map_time:.1f}ç§’")
                
                self.map_history.append(map_results)
                self.map_epochs.append(epoch + 1)
                print(f"  ğŸ“Š mAP: {map_results['mAP']:.4f}")
                
                # é¢å¤–åˆ†æï¼ˆé™ä½é¢‘ç‡ï¼‰
                if (epoch + 1) % 6 == 0:  # æ¯6è½®è¯¦ç»†åˆ†æä¸€æ¬¡
                    self._analyze_class_predictions(val_loader, epoch + 1)
            else:
                # ä¸è®¡ç®—mAPçš„è½®æ¬¡ï¼Œå¤ç”¨ä¸Šä¸€æ¬¡çš„å€¼
                if len(self.map_history) > 0:
                    self.map_history.append(self.map_history[-1])
                    self.map_epochs.append(epoch + 1)
                else:
                    self.map_history.append({'mAP': 0.0})
                    self.map_epochs.append(epoch + 1)
                
                print(f"  â­ï¸ è·³è¿‡SwinYOLO mAPè®¡ç®— (ç¬¬{epoch+1}è½®)")
            
            # æ¯10ä¸ªepochç”Ÿæˆå®æ—¶å›¾è¡¨
            if (epoch + 1) % 10 == 0:
                self.plot_real_time_results(epoch + 1)
            
            # æ¯10ä¸ªepochä¿å­˜ä¸€æ¬¡
            if (epoch + 1) % 10 == 0 or is_best:
                self.save_checkpoint(epoch + 1, optimizer, scheduler, best_loss, is_best)
            
            print()
        
        print("ğŸ‰ è®­ç»ƒå®Œæˆ!")
        print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_loss:.4f}")
        
        # åˆ›å»ºæœ€ç»ˆå¯è§†åŒ–
        final_vis_dir = self.create_final_visualization()
        
        # ä¿å­˜å®Œæ•´è®­ç»ƒå†å²
        history_path = os.path.join(self.save_dir, 'training_history.json')
        with open(history_path, 'w') as f:
            json.dump({
                'train_losses': self.train_losses,
                'val_losses': self.val_losses,
                'learning_rates': self.learning_rates,
                'train_losses_detailed': self.train_losses_detailed,
                'val_losses_detailed': self.val_losses_detailed,
                'map_history': self.map_history,
                'map_epochs': self.map_epochs,
                'best_loss': best_loss,
                'final_visualization_dir': final_vis_dir
            }, f, indent=2)
        
        print(f"ğŸ“Š è®­ç»ƒå†å²å·²ä¿å­˜åˆ°: {history_path}")
        print(f"ğŸ¨ æœ€ç»ˆå¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {final_vis_dir}")
    
    def _analyze_class_predictions(self, val_loader, epoch):
        """åˆ†ææ¨¡å‹çš„ç±»åˆ«é¢„æµ‹æƒ…å†µ"""
        print(f"ğŸ” Epoch {epoch} - è¯¦ç»†ç±»åˆ«é¢„æµ‹åˆ†æ:")
        
        self.model.eval()
        class_prediction_counts = {}
        class_confidence_sums = {}
        total_predictions = 0
        
        with torch.no_grad():
            # åªåˆ†æå‰å‡ ä¸ªbatchï¼Œé¿å…å¤ªæ…¢
            for batch_idx, (images, targets) in enumerate(val_loader):
                if batch_idx >= 3:  # åªåˆ†æå‰3ä¸ªbatch
                    break
                    
                images = images.to(self.device)
                predictions = self.model(images)
                
                # è§£ç é¢„æµ‹ç»“æœ
                batch_detections = decode_predictions(
                    predictions, 
                    conf_threshold=0.001  # ä½¿ç”¨å¾ˆä½çš„é˜ˆå€¼çœ‹æ‰€æœ‰é¢„æµ‹
                )
                
                for detections in batch_detections:
                    for det in detections:
                        class_id = det['class_id']
                        confidence = det['score']
                        
                        if class_id not in class_prediction_counts:
                            class_prediction_counts[class_id] = 0
                            class_confidence_sums[class_id] = 0.0
                        
                        class_prediction_counts[class_id] += 1
                        class_confidence_sums[class_id] += confidence
                        total_predictions += 1
        
        if total_predictions > 0:
            print(f"   æ€»é¢„æµ‹æ•°: {total_predictions}")
            print(f"   é¢„æµ‹ç±»åˆ«æ•°: {len(class_prediction_counts)}/20")
            
            # æ˜¾ç¤ºtopé¢„æµ‹ç±»åˆ«
            sorted_classes = sorted(class_prediction_counts.items(), 
                                  key=lambda x: x[1], reverse=True)
            
            voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',
                          'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']
            
            print("   Topé¢„æµ‹ç±»åˆ«:")
            for i, (class_id, count) in enumerate(sorted_classes[:5]):
                avg_conf = class_confidence_sums[class_id] / count
                percentage = (count / total_predictions) * 100
                class_name = voc_classes[class_id] if class_id < len(voc_classes) else f'class_{class_id}'
                print(f"     {class_id}({class_name}): {count}æ¬¡({percentage:.1f}%), å¹³å‡ç½®ä¿¡åº¦:{avg_conf:.3f}")
        else:
            print("   âŒ æ²¡æœ‰ä»»ä½•é¢„æµ‹ç»“æœ!")
        
        print()


def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # é…ç½®å‚æ•°
    config = {
        'num_classes': 20,  # VOCæ•°æ®é›†
        'input_size': 448,
        'grid_size': 7,
        'batch_size': 16,  # æ ¹æ®GPUå†…å­˜è°ƒæ•´
        'epochs': 100,
        'base_lr': 0.001,
        'backbone_lr_ratio': 0.1,
        'weight_decay': 0.0005,
        'freeze_backbone_epochs': 10
    }
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = SwinYOLOTrainer(
        num_classes=config['num_classes'],
        input_size=config['input_size'],
        grid_size=config['grid_size']
    )
    
    # æ•°æ®é›†é…ç½®ï¼ˆéœ€è¦æ ¹æ®å®é™…è·¯å¾„è°ƒæ•´ï¼‰
    try:
        # åŠ è½½å®Œæ•´æ•°æ®é›†
        full_dataset = VOC_Detection_Set(
            voc2012_jpeg_dir='../../data/VOC2012/VOCdevkit/VOC2012/JPEGImages',
            voc2012_anno_dir='../../data/VOC2012/VOCdevkit/VOC2012/Annotations', 
            class_file='voc_classes.txt',
            input_size=config['input_size'],
            grid_size=config['grid_size'],
            is_train=True
        )
        
        # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆ80%è®­ç»ƒï¼Œ20%éªŒè¯ï¼‰
        from torch.utils.data import random_split
        
        total_size = len(full_dataset)
        train_size = int(0.8 * total_size)
        val_size = total_size - train_size
        
        train_dataset, val_dataset = random_split(
            full_dataset, 
            [train_size, val_size],
            generator=torch.Generator().manual_seed(42)  # å›ºå®šéšæœºç§å­ä¿è¯å¯é‡å¤æ€§
        )
        
        print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ")
        print(f"   æ€»æ ·æœ¬æ•°: {total_size}")
        print(f"   è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬ ({train_size/total_size*100:.1f}%)")
        print(f"   éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬ ({val_size/total_size*100:.1f}%)")
        
        # ğŸ” æ£€æŸ¥æ•°æ®é›†ç±»åˆ«åˆ†å¸ƒ
        analyze_dataset_distribution(full_dataset)
        
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        print("ä½¿ç”¨è™šæ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º...")
        
        # åˆ›å»ºè™šæ‹Ÿæ•°æ®é›†
        from torch.utils.data import TensorDataset
        
        # è™šæ‹Ÿè®­ç»ƒé›†ï¼ˆ80%ï¼‰
        train_images = torch.randn(800, 3, config['input_size'], config['input_size'])
        train_targets = torch.randn(800, config['grid_size'], config['grid_size'], 
                                   2*5 + config['num_classes'])  # åº”è¯¥æ˜¯30ç»´ï¼š10(è¾¹ç•Œæ¡†) + 20(ç±»åˆ«)
        train_dataset = TensorDataset(train_images, train_targets)
        
        # è™šæ‹ŸéªŒè¯é›†ï¼ˆ20%ï¼‰
        val_images = torch.randn(200, 3, config['input_size'], config['input_size'])
        val_targets = torch.randn(200, config['grid_size'], config['grid_size'],
                                 2*5 + config['num_classes'])  # åº”è¯¥æ˜¯30ç»´ï¼š10(è¾¹ç•Œæ¡†) + 20(ç±»åˆ«)
        val_dataset = TensorDataset(val_images, val_targets)
        
        print(f"âœ… è™šæ‹Ÿæ•°æ®é›†åˆ›å»ºæˆåŠŸ")
        print(f"   è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
        print(f"   éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=4,
        pin_memory=True,
        collate_fn=custom_collate_fn
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=4,
        pin_memory=True,
        collate_fn=custom_collate_fn
    )
    
    # å¼€å§‹è®­ç»ƒ
    trainer.train(
        train_loader=train_loader,
        val_loader=val_loader,
        epochs=config['epochs'],
        base_lr=config['base_lr'],
        backbone_lr_ratio=config['backbone_lr_ratio'],
        weight_decay=config['weight_decay'],
        freeze_backbone_epochs=config['freeze_backbone_epochs']
    )


def analyze_dataset_distribution(dataset, sample_size=200):
    """åˆ†ææ•°æ®é›†ä¸­çš„ç±»åˆ«åˆ†å¸ƒ"""
    from collections import Counter
    import random
    
    print(f"ğŸ“Š åˆ†ææ•°æ®é›†ç±»åˆ«åˆ†å¸ƒ (é‡‡æ ·{min(sample_size, len(dataset))}ä¸ªæ ·æœ¬)...")
    
    class_counts = Counter()
    sample_indices = random.sample(range(len(dataset)), min(sample_size, len(dataset)))
    
    voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow',
                   'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']
    
    for idx in sample_indices:
        try:
            _, targets = dataset[idx]  # targets = [gt, mask_pos, mask_neg]
            gt = targets[0]  # è·å–ground truth
            
            # éå†ç½‘æ ¼æ‰¾åˆ°æœ‰å¯¹è±¡çš„ä½ç½®
            grid_size = gt.size(0)
            for i in range(grid_size):
                for j in range(grid_size):
                    # æ£€æŸ¥ç½®ä¿¡åº¦ (ç¬¬4å’Œç¬¬9ä¸ªä½ç½®æ˜¯ä¸¤ä¸ªboxçš„ç½®ä¿¡åº¦)
                    conf1 = gt[i, j, 4].item()
                    conf2 = gt[i, j, 9].item()
                    
                    if conf1 > 0.5 or conf2 > 0.5:  # å¦‚æœæœ‰å¯¹è±¡
                        # è·å–ç±»åˆ« (ç¬¬10ä½å¼€å§‹æ˜¯20ä¸ªç±»åˆ«çš„one-hot)
                        class_probs = gt[i, j, 10:30]
                        class_id = torch.argmax(class_probs).item()
                        class_counts[class_id] += 1
                        
        except Exception as e:
            continue
    
    # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
    total_objects = sum(class_counts.values())
    print(f"   å‘ç°å¯¹è±¡æ€»æ•°: {total_objects}")
    print(f"   åŒ…å«ç±»åˆ«æ•°: {len(class_counts)}/20")
    
    if class_counts:
        print("   ç±»åˆ«åˆ†å¸ƒ (å‰10):")
        for class_id, count in class_counts.most_common(10):
            if class_id < len(voc_classes):
                class_name = voc_classes[class_id]
                percentage = (count / total_objects) * 100
                print(f"     {class_id:2d}({class_name:12s}): {count:3d} ({percentage:5.1f}%)")
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¸¥é‡ä¸å¹³è¡¡
        max_count = max(class_counts.values())
        min_count = min(class_counts.values()) if class_counts else 0
        if max_count > min_count * 10:
            print(f"   âš ï¸  æ•°æ®ä¸å¹³è¡¡ä¸¥é‡! æœ€å¤šç±»åˆ«{max_count}ä¸ªï¼Œæœ€å°‘ç±»åˆ«{min_count}ä¸ª")
            print(f"   è¿™å¯èƒ½å¯¼è‡´æ¨¡å‹åå‘é¢‘ç¹ç±»åˆ«")
    else:
        print(f"   âŒ æœªæ‰¾åˆ°ä»»ä½•å¯¹è±¡! æ•°æ®é›†å¯èƒ½æœ‰é—®é¢˜")
    
    print()


if __name__ == "__main__":
    main()
