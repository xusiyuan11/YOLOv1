"""
SwinYOLOè®­ç»ƒè„šæœ¬
ç®€åŒ–çš„è®­ç»ƒæµç¨‹ï¼Œä¸“æ³¨äºSwin Transformer + YOLOæ£€æµ‹
"""

import torch
import torch.optim as optim
from torch.utils.data import DataLoader
import os
import time
from tqdm import tqdm
import json
import numpy as np

from SwinYOLO import create_swin_yolo
from dataset import VOC_Detection_Set  # ä½¿ç”¨ç°æœ‰çš„æ•°æ®é›†
from evaluation import evaluate_model, decode_predictions, apply_nms_to_detections
from visualization import (plot_training_curves, plot_loss_components, plot_map_curves, 
                          create_training_summary_plot, plot_class_wise_performance)


def custom_collate_fn(batch):
    """è‡ªå®šä¹‰çš„collateå‡½æ•°ï¼Œæ­£ç¡®å¤„ç†[gt, mask_pos, mask_neg]æ ¼å¼çš„targets"""
    images = []
    targets = []
    
    for sample in batch:
        img, target_data = sample
        images.append(img)
        
        # æ£€æŸ¥target_dataçš„ç±»å‹
        if isinstance(target_data, list) and len(target_data) == 3:
            # çœŸå®æ•°æ®é›†æ ¼å¼: [gt, mask_pos, mask_neg]
            targets.append(target_data)
        elif isinstance(target_data, torch.Tensor):
            # è™šæ‹Ÿæ•°æ®é›†æ ¼å¼: ç›´æ¥æ˜¯ä¸€ä¸ªå¼ é‡
            # å°†å…¶è½¬æ¢ä¸ºå…¼å®¹æ ¼å¼
            targets.append(target_data)
        else:
            targets.append(target_data)
    
    # å°†å›¾åƒå †å ä¸ºæ‰¹å¤„ç†å¼ é‡
    images = torch.stack(images)
    
    return images, targets


class SwinYOLOTrainer:
    """SwinYOLOè®­ç»ƒå™¨"""
    
    def __init__(self, 
                 num_classes=20,
                 input_size=448,
                 grid_size=7,
                 device='cuda',
                 save_dir='./checkpoints/swin_yolo'):
        
        self.num_classes = num_classes
        self.input_size = input_size
        self.grid_size = grid_size
        self.device = torch.device(device if torch.cuda.is_available() else 'cpu')
        self.save_dir = save_dir
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(save_dir, exist_ok=True)
        
        # åˆ›å»ºæ¨¡å‹å’ŒæŸå¤±å‡½æ•°
        self.model, self.loss_fn = create_swin_yolo(
            num_classes=num_classes,
            input_size=input_size,
            grid_size=grid_size
        )
        self.model.to(self.device)
        self.loss_fn.to(self.device)
        
        # è®­ç»ƒç»Ÿè®¡
        self.train_losses = []
        self.val_losses = []
        self.learning_rates = []
        
        # è¯¦ç»†æŸå¤±è®°å½•
        self.train_losses_detailed = {
            'total_loss': [],
            'coord_loss': [],
            'conf_loss': [],
            'class_loss': []
        }
        self.val_losses_detailed = {
            'total_loss': [],
            'coord_loss': [],
            'conf_loss': [],
            'class_loss': []
        }
        
        # mAPè®°å½•
        self.map_history = []
        self.map_epochs = []
        
        print(f"âœ… SwinYOLOè®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   è®¾å¤‡: {self.device}")
        print(f"   æ¨¡å‹å‚æ•°: {sum(p.numel() for p in self.model.parameters()):,}")
        print(f"   ä¿å­˜ç›®å½•: {self.save_dir}")
    
    def create_optimizer(self, base_lr=0.001, backbone_lr_ratio=0.1, weight_decay=0.0005):
        """åˆ›å»ºä¼˜åŒ–å™¨ï¼Œä½¿ç”¨ä¸åŒçš„å­¦ä¹ ç‡"""
        param_groups = self.model.get_parameter_groups(base_lr, backbone_lr_ratio)
        
        optimizer = optim.Adam([
            {'params': group['params'], 'lr': group['lr']} 
            for group in param_groups
        ], weight_decay=weight_decay)
        
        return optimizer
    
    def create_scheduler(self, optimizer, epochs):
        """åˆ›å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        scheduler = optim.lr_scheduler.CosineAnnealingLR(
            optimizer, 
            T_max=epochs,
            eta_min=1e-6
        )
        return scheduler
    
    def train_epoch(self, train_loader, optimizer, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0.0
        total_coord_loss = 0.0
        total_conf_loss = 0.0
        total_class_loss = 0.0
        
        progress_bar = tqdm(train_loader, desc=f'è®­ç»ƒ Epoch {epoch+1}')
        
        for batch_idx, (images, targets) in enumerate(progress_bar):
            images = images.to(self.device)
            
            # å¤„ç†targetsï¼šæ”¯æŒä¸¤ç§æ ¼å¼
            if isinstance(targets, list) and len(targets) > 0:
                # æ£€æŸ¥ç¬¬ä¸€ä¸ªtargetçš„æ ¼å¼æ¥ç¡®å®šæ•°æ®ç±»å‹
                first_target = targets[0]
                
                if isinstance(first_target, list) and len(first_target) == 3:
                    # çœŸå®æ•°æ®é›†æ ¼å¼: [gt, mask_pos, mask_neg]
                    batch_gt = []
                    batch_mask_pos = []
                    batch_mask_neg = []
                    
                    for target in targets:
                        gt, mask_pos, mask_neg = target
                        # ç¡®ä¿gtæ˜¯tensor
                        if isinstance(gt, np.ndarray):
                            gt = torch.from_numpy(gt).float()
                        batch_gt.append(gt)
                        batch_mask_pos.append(mask_pos)
                        batch_mask_neg.append(mask_neg)
                    
                    # å †å ä¸ºæ‰¹å¤„ç†å¼ é‡
                    targets = [
                        torch.stack(batch_gt),
                        torch.stack(batch_mask_pos), 
                        torch.stack(batch_mask_neg)
                    ]
                    
                elif isinstance(first_target, torch.Tensor):
                    # è™šæ‹Ÿæ•°æ®é›†æ ¼å¼: ç›´æ¥æ˜¯å¼ é‡
                    targets = torch.stack(targets)
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„targetæ ¼å¼: {type(first_target)}")
            
            # å°†targetsç§»åŠ¨åˆ°è®¾å¤‡
            if isinstance(targets, list):
                targets = [t.to(self.device) for t in targets]
            else:
                targets = targets.to(self.device)
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            predictions = self.model(images)
            
            # è®¡ç®—æŸå¤±
            # targetsç°åœ¨æ˜¯[batch_gt, batch_mask_pos, batch_mask_neg]çš„åˆ—è¡¨
            if isinstance(targets, list) and len(targets) >= 1:
                # ä½¿ç”¨gtä½œä¸ºä¸»è¦ç›®æ ‡ï¼Œmaskç”¨äºå…¶ä»–ç›®çš„
                gt_targets = targets[0]  # batch_gt
                loss_dict = self.loss_fn(predictions, gt_targets)
            else:
                loss_dict = self.loss_fn(predictions, targets)
            loss = loss_dict['total_loss']
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            total_coord_loss += loss_dict['coord_loss'].item()
            total_conf_loss += loss_dict['conf_loss'].item()
            total_class_loss += loss_dict['class_loss'].item()
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'Coord': f'{loss_dict["coord_loss"].item():.4f}',
                'Conf': f'{loss_dict["conf_loss"].item():.4f}',
                'Class': f'{loss_dict["class_loss"].item():.4f}'
            })
        
        avg_loss = total_loss / len(train_loader)
        avg_coord_loss = total_coord_loss / len(train_loader)
        avg_conf_loss = total_conf_loss / len(train_loader)
        avg_class_loss = total_class_loss / len(train_loader)
        
        return {
            'total_loss': avg_loss,
            'coord_loss': avg_coord_loss,
            'conf_loss': avg_conf_loss,
            'class_loss': avg_class_loss
        }
    
    def validate_epoch(self, val_loader, epoch):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        total_loss = 0.0
        total_coord_loss = 0.0
        total_conf_loss = 0.0
        total_class_loss = 0.0
        
        with torch.no_grad():
            progress_bar = tqdm(val_loader, desc=f'éªŒè¯ Epoch {epoch+1}')
            
            for images, targets in progress_bar:
                images = images.to(self.device)
                
                # å¤„ç†targetsï¼šæ”¯æŒä¸¤ç§æ ¼å¼
                if isinstance(targets, list) and len(targets) > 0:
                    # æ£€æŸ¥ç¬¬ä¸€ä¸ªtargetçš„æ ¼å¼æ¥ç¡®å®šæ•°æ®ç±»å‹
                    first_target = targets[0]
                    
                    if isinstance(first_target, list) and len(first_target) == 3:
                        # çœŸå®æ•°æ®é›†æ ¼å¼: [gt, mask_pos, mask_neg]
                        batch_gt = []
                        batch_mask_pos = []
                        batch_mask_neg = []
                        
                        for target in targets:
                            gt, mask_pos, mask_neg = target
                            # ç¡®ä¿gtæ˜¯tensor
                            if isinstance(gt, np.ndarray):
                                gt = torch.from_numpy(gt).float()
                            batch_gt.append(gt)
                            batch_mask_pos.append(mask_pos)
                            batch_mask_neg.append(mask_neg)
                        
                        # å †å ä¸ºæ‰¹å¤„ç†å¼ é‡
                        targets = [
                            torch.stack(batch_gt),
                            torch.stack(batch_mask_pos), 
                            torch.stack(batch_mask_neg)
                        ]
                        
                    elif isinstance(first_target, torch.Tensor):
                        # è™šæ‹Ÿæ•°æ®é›†æ ¼å¼: ç›´æ¥æ˜¯å¼ é‡
                        targets = torch.stack(targets)
                    else:
                        raise ValueError(f"ä¸æ”¯æŒçš„targetæ ¼å¼: {type(first_target)}")
                
                # å°†targetsç§»åŠ¨åˆ°è®¾å¤‡
                if isinstance(targets, list):
                    targets = [t.to(self.device) for t in targets]
                else:
                    targets = targets.to(self.device)
                
                predictions = self.model(images)
                
                # è®¡ç®—æŸå¤±
                if isinstance(targets, list) and len(targets) >= 1:
                    # ä½¿ç”¨gtä½œä¸ºä¸»è¦ç›®æ ‡
                    gt_targets = targets[0]  # batch_gt
                    loss_dict = self.loss_fn(predictions, gt_targets)
                else:
                    loss_dict = self.loss_fn(predictions, targets)
                
                total_loss += loss_dict['total_loss'].item()
                total_coord_loss += loss_dict['coord_loss'].item()
                total_conf_loss += loss_dict['conf_loss'].item()
                total_class_loss += loss_dict['class_loss'].item()
                
                progress_bar.set_postfix({
                    'Val Loss': f'{loss_dict["total_loss"].item():.4f}'
                })
        
        avg_loss = total_loss / len(val_loader)
        avg_coord_loss = total_coord_loss / len(val_loader)
        avg_conf_loss = total_conf_loss / len(val_loader)
        avg_class_loss = total_class_loss / len(val_loader)
        
        return {
            'total_loss': avg_loss,
            'coord_loss': avg_coord_loss,
            'conf_loss': avg_conf_loss,
            'class_loss': avg_class_loss
        }
    
    def evaluate_map(self, val_loader, conf_threshold=0.1, iou_threshold=0.5):
        """è¯„ä¼°æ¨¡å‹çš„mAPæŒ‡æ ‡"""
        print("ğŸ“Š å¼€å§‹è¯„ä¼°mAP...")
        
        map_results = evaluate_model(
            model=self.model,
            dataloader=val_loader,
            device=self.device,
            num_classes=self.num_classes,
            conf_threshold=conf_threshold,
            iou_threshold=iou_threshold
        )
        
        print(f"âœ… mAPè¯„ä¼°å®Œæˆ:")
        print(f"   mAP@0.5: {map_results['mAP']:.4f}")
        
        # æ˜¾ç¤ºå‰5ä¸ªç±»åˆ«çš„AP
        class_aps = [(k, v) for k, v in map_results.items() if k.startswith('class_')]
        class_aps.sort(key=lambda x: x[1], reverse=True)
        
        print("   Top 5 ç±»åˆ«AP:")
        for i, (class_name, ap) in enumerate(class_aps[:5]):
            class_id = int(class_name.split('_')[1])
            print(f"     ç±»åˆ«{class_id}: {ap:.4f}")
        
        return map_results
    
    def plot_real_time_results(self, current_epoch):
        """ç»˜åˆ¶å®æ—¶è®­ç»ƒç»“æœ"""
        print(f"ğŸ“Š ç”ŸæˆEpoch {current_epoch}çš„è®­ç»ƒå›¾è¡¨...")
        
        vis_dir = os.path.join(self.save_dir, 'visualizations')
        os.makedirs(vis_dir, exist_ok=True)
        
        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        if len(self.train_losses) > 1:
            train_curve_path = os.path.join(vis_dir, f'training_curves_epoch_{current_epoch}.png')
            plot_training_curves(
                self.train_losses, 
                self.val_losses,
                self.learning_rates if self.learning_rates else None,
                save_path=train_curve_path,
                title=f"SwinYOLOè®­ç»ƒæ›²çº¿ (Epoch {current_epoch})"
            )
        
        # ç»˜åˆ¶æŸå¤±ç»„ä»¶
        if len(self.train_losses_detailed['total_loss']) > 1:
            components_path = os.path.join(vis_dir, f'loss_components_epoch_{current_epoch}.png')
            plot_loss_components(
                self.train_losses_detailed,
                self.val_losses_detailed,
                save_path=components_path,
                title=f"SwinYOLOæŸå¤±ç»„ä»¶ (Epoch {current_epoch})"
            )
        
        # ç»˜åˆ¶mAPæ›²çº¿
        if len(self.map_history) > 1:
            map_path = os.path.join(vis_dir, f'map_curves_epoch_{current_epoch}.png')
            plot_map_curves(
                self.map_history,
                save_path=map_path,
                title=f"SwinYOLO mAPæ›²çº¿ (Epoch {current_epoch})"
            )
            
            # æœ€æ–°çš„ç±»åˆ«æ€§èƒ½åˆ†æ
            latest_map = self.map_history[-1]
            class_perf_path = os.path.join(vis_dir, f'class_performance_epoch_{current_epoch}.png')
            plot_class_wise_performance(
                latest_map,
                save_path=class_perf_path,
                title=f"å„ç±»åˆ«æ€§èƒ½åˆ†æ (Epoch {current_epoch})"
            )
    
    def create_final_visualization(self):
        """åˆ›å»ºè®­ç»ƒå®Œæˆåçš„å®Œæ•´å¯è§†åŒ–"""
        print("ğŸ¨ åˆ›å»ºæœ€ç»ˆè®­ç»ƒå¯è§†åŒ–...")
        
        vis_dir = os.path.join(self.save_dir, 'final_results')
        os.makedirs(vis_dir, exist_ok=True)
        
        # æœ€ç»ˆè®­ç»ƒæ›²çº¿
        final_train_path = os.path.join(vis_dir, 'final_training_curves.png')
        plot_training_curves(
            self.train_losses, 
            self.val_losses,
            self.learning_rates if self.learning_rates else None,
            save_path=final_train_path,
            title="SwinYOLOæœ€ç»ˆè®­ç»ƒæ›²çº¿"
        )
        
        # æœ€ç»ˆæŸå¤±ç»„ä»¶
        final_components_path = os.path.join(vis_dir, 'final_loss_components.png')
        plot_loss_components(
            self.train_losses_detailed,
            self.val_losses_detailed,
            save_path=final_components_path,
            title="SwinYOLOæœ€ç»ˆæŸå¤±ç»„ä»¶"
        )
        
        # æœ€ç»ˆmAPæ›²çº¿
        if self.map_history:
            final_map_path = os.path.join(vis_dir, 'final_map_curves.png')
            plot_map_curves(
                self.map_history,
                save_path=final_map_path,
                title="SwinYOLOæœ€ç»ˆmAPæ›²çº¿"
            )
            
            # æœ€ç»ˆç±»åˆ«æ€§èƒ½
            final_class_path = os.path.join(vis_dir, 'final_class_performance.png')
            final_map = self.map_history[-1]
            plot_class_wise_performance(
                final_map,
                save_path=final_class_path,
                title="æœ€ç»ˆå„ç±»åˆ«æ€§èƒ½åˆ†æ"
            )
            
            print(f"ğŸ† æœ€ä½³mAP: {max(result['mAP'] for result in self.map_history):.4f}")
        
        return vis_dir
    
    def save_checkpoint(self, epoch, optimizer, scheduler, best_loss, is_best=False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict() if scheduler else None,
            'best_loss': best_loss,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'learning_rates': self.learning_rates,
            'config': {
                'num_classes': self.num_classes,
                'input_size': self.input_size,
                'grid_size': self.grid_size
            }
        }
        
        # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
        latest_path = os.path.join(self.save_dir, 'latest_checkpoint.pth')
        torch.save(checkpoint, latest_path)
        
        # ä¿å­˜æœ€ä½³æ£€æŸ¥ç‚¹
        if is_best:
            best_path = os.path.join(self.save_dir, 'best_checkpoint.pth')
            torch.save(checkpoint, best_path)
            print(f"âœ… æœ€ä½³æ¨¡å‹å·²ä¿å­˜: {best_path}")
    
    def load_checkpoint(self, checkpoint_path, optimizer=None, scheduler=None):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        
        if optimizer and 'optimizer_state_dict' in checkpoint:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        if scheduler and 'scheduler_state_dict' in checkpoint:
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        self.train_losses = checkpoint.get('train_losses', [])
        self.val_losses = checkpoint.get('val_losses', [])
        self.learning_rates = checkpoint.get('learning_rates', [])
        
        return checkpoint['epoch'], checkpoint.get('best_loss', float('inf'))
    
    def train(self, 
              train_loader, 
              val_loader, 
              epochs=100,
              base_lr=0.001,
              backbone_lr_ratio=0.1,
              weight_decay=0.0005,
              resume_from=None,
              freeze_backbone_epochs=10):
        """
        è®­ç»ƒSwinYOLO
        
        Args:
            train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨
            val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨
            epochs: è®­ç»ƒè½®æ•°
            base_lr: åŸºç¡€å­¦ä¹ ç‡
            backbone_lr_ratio: backboneå­¦ä¹ ç‡æ¯”ä¾‹
            weight_decay: æƒé‡è¡°å‡
            resume_from: æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„
            freeze_backbone_epochs: å†»ç»“backboneçš„è½®æ•°
        """
        print("="*60)
        print("ğŸš€ å¼€å§‹SwinYOLOè®­ç»ƒ")
        print("="*60)
        
        # åˆ›å»ºä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        optimizer = self.create_optimizer(base_lr, backbone_lr_ratio, weight_decay)
        scheduler = self.create_scheduler(optimizer, epochs)
        
        # æ¢å¤è®­ç»ƒ
        start_epoch = 0
        best_loss = float('inf')
        
        if resume_from and os.path.exists(resume_from):
            print(f"ğŸ“ ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ: {resume_from}")
            start_epoch, best_loss = self.load_checkpoint(resume_from, optimizer, scheduler)
        
        # å‰å‡ ä¸ªepochå†»ç»“backbone
        if start_epoch < freeze_backbone_epochs:
            self.model.freeze_backbone()
            print(f"ğŸ”’ å‰{freeze_backbone_epochs}ä¸ªepochå°†å†»ç»“Swin backbone")
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(start_epoch, epochs):
            # è§£å†»backbone
            if epoch == freeze_backbone_epochs:
                self.model.unfreeze_backbone()
                print(f"ğŸ”“ Epoch {epoch}: è§£å†»Swin backboneï¼Œå¼€å§‹ç«¯åˆ°ç«¯è®­ç»ƒ")
            
            # è®­ç»ƒ
            train_metrics = self.train_epoch(train_loader, optimizer, epoch)
            
            # éªŒè¯
            val_metrics = self.validate_epoch(val_loader, epoch)
            
            # æ›´æ–°å­¦ä¹ ç‡
            if scheduler:
                scheduler.step()
                current_lr = scheduler.get_last_lr()[0]
                self.learning_rates.append(current_lr)
            
            # è®°å½•æŸå¤±
            self.train_losses.append(train_metrics['total_loss'])
            self.val_losses.append(val_metrics['total_loss'])
            
            # è®°å½•è¯¦ç»†æŸå¤±
            for key in self.train_losses_detailed.keys():
                self.train_losses_detailed[key].append(train_metrics[key])
                self.val_losses_detailed[key].append(val_metrics[key])
            
            # æ‰“å°ç»“æœ
            print(f"Epoch {epoch+1}/{epochs}:")
            print(f"  è®­ç»ƒ - æ€»æŸå¤±: {train_metrics['total_loss']:.4f}, "
                  f"åæ ‡: {train_metrics['coord_loss']:.4f}, "
                  f"ç½®ä¿¡åº¦: {train_metrics['conf_loss']:.4f}, "
                  f"åˆ†ç±»: {train_metrics['class_loss']:.4f}")
            print(f"  éªŒè¯ - æ€»æŸå¤±: {val_metrics['total_loss']:.4f}, "
                  f"åæ ‡: {val_metrics['coord_loss']:.4f}, "
                  f"ç½®ä¿¡åº¦: {val_metrics['conf_loss']:.4f}, "
                  f"åˆ†ç±»: {val_metrics['class_loss']:.4f}")
            if scheduler:
                print(f"  å­¦ä¹ ç‡: {current_lr:.6f}")
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            is_best = val_metrics['total_loss'] < best_loss
            if is_best:
                best_loss = val_metrics['total_loss']
            
            # æ¯5ä¸ªepochè¿›è¡ŒmAPè¯„ä¼° (æ›´é¢‘ç¹)
            if (epoch + 1) % 5 == 0:
                map_results = self.evaluate_map(val_loader, conf_threshold=0.1, iou_threshold=0.5)
                self.map_history.append(map_results)
                self.map_epochs.append(epoch + 1)
                print(f"  Epoch {epoch+1} mAP: {map_results['mAP']:.4f}")
                
                # æ¯10ä¸ªepochç”Ÿæˆå®æ—¶å›¾è¡¨
                if (epoch + 1) % 10 == 0:
                    self.plot_real_time_results(epoch + 1)
            
            # æ¯10ä¸ªepochä¿å­˜ä¸€æ¬¡
            if (epoch + 1) % 10 == 0 or is_best:
                self.save_checkpoint(epoch + 1, optimizer, scheduler, best_loss, is_best)
            
            print()
        
        print("ğŸ‰ è®­ç»ƒå®Œæˆ!")
        print(f"æœ€ä½³éªŒè¯æŸå¤±: {best_loss:.4f}")
        
        # åˆ›å»ºæœ€ç»ˆå¯è§†åŒ–
        final_vis_dir = self.create_final_visualization()
        
        # ä¿å­˜å®Œæ•´è®­ç»ƒå†å²
        history_path = os.path.join(self.save_dir, 'training_history.json')
        with open(history_path, 'w') as f:
            json.dump({
                'train_losses': self.train_losses,
                'val_losses': self.val_losses,
                'learning_rates': self.learning_rates,
                'train_losses_detailed': self.train_losses_detailed,
                'val_losses_detailed': self.val_losses_detailed,
                'map_history': self.map_history,
                'map_epochs': self.map_epochs,
                'best_loss': best_loss,
                'final_visualization_dir': final_vis_dir
            }, f, indent=2)
        
        print(f"ğŸ“Š è®­ç»ƒå†å²å·²ä¿å­˜åˆ°: {history_path}")
        print(f"ğŸ¨ æœ€ç»ˆå¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {final_vis_dir}")


def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # é…ç½®å‚æ•°
    config = {
        'num_classes': 20,  # VOCæ•°æ®é›†
        'input_size': 448,
        'grid_size': 7,
        'batch_size': 16,  # æ ¹æ®GPUå†…å­˜è°ƒæ•´
        'epochs': 100,
        'base_lr': 0.001,
        'backbone_lr_ratio': 0.1,
        'weight_decay': 0.0005,
        'freeze_backbone_epochs': 10
    }
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = SwinYOLOTrainer(
        num_classes=config['num_classes'],
        input_size=config['input_size'],
        grid_size=config['grid_size']
    )
    
    # æ•°æ®é›†é…ç½®ï¼ˆéœ€è¦æ ¹æ®å®é™…è·¯å¾„è°ƒæ•´ï¼‰
    try:
        # åŠ è½½å®Œæ•´æ•°æ®é›†
        full_dataset = VOC_Detection_Set(
            voc2012_jpeg_dir='../../data/VOC2012/VOCdevkit/VOC2012/JPEGImages',
            voc2012_anno_dir='../../data/VOC2012/VOCdevkit/VOC2012/Annotations', 
            class_file='voc_classes.txt',
            input_size=config['input_size'],
            grid_size=config['grid_size'],
            is_train=True
        )
        
        # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆ80%è®­ç»ƒï¼Œ20%éªŒè¯ï¼‰
        from torch.utils.data import random_split
        
        total_size = len(full_dataset)
        train_size = int(0.8 * total_size)
        val_size = total_size - train_size
        
        train_dataset, val_dataset = random_split(
            full_dataset, 
            [train_size, val_size],
            generator=torch.Generator().manual_seed(42)  # å›ºå®šéšæœºç§å­ä¿è¯å¯é‡å¤æ€§
        )
        
        print(f"âœ… æ•°æ®é›†åŠ è½½æˆåŠŸ")
        print(f"   æ€»æ ·æœ¬æ•°: {total_size}")
        print(f"   è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬ ({train_size/total_size*100:.1f}%)")
        print(f"   éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬ ({val_size/total_size*100:.1f}%)")
        
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        print("ä½¿ç”¨è™šæ‹Ÿæ•°æ®è¿›è¡Œæ¼”ç¤º...")
        
        # åˆ›å»ºè™šæ‹Ÿæ•°æ®é›†
        from torch.utils.data import TensorDataset
        
        # è™šæ‹Ÿè®­ç»ƒé›†ï¼ˆ80%ï¼‰
        train_images = torch.randn(800, 3, config['input_size'], config['input_size'])
        train_targets = torch.randn(800, config['grid_size'], config['grid_size'], 
                                   2*5 + config['num_classes'])  # åº”è¯¥æ˜¯30ç»´ï¼š10(è¾¹ç•Œæ¡†) + 20(ç±»åˆ«)
        train_dataset = TensorDataset(train_images, train_targets)
        
        # è™šæ‹ŸéªŒè¯é›†ï¼ˆ20%ï¼‰
        val_images = torch.randn(200, 3, config['input_size'], config['input_size'])
        val_targets = torch.randn(200, config['grid_size'], config['grid_size'],
                                 2*5 + config['num_classes'])  # åº”è¯¥æ˜¯30ç»´ï¼š10(è¾¹ç•Œæ¡†) + 20(ç±»åˆ«)
        val_dataset = TensorDataset(val_images, val_targets)
        
        print(f"âœ… è™šæ‹Ÿæ•°æ®é›†åˆ›å»ºæˆåŠŸ")
        print(f"   è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
        print(f"   éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬")
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=4,
        pin_memory=True,
        collate_fn=custom_collate_fn
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=4,
        pin_memory=True,
        collate_fn=custom_collate_fn
    )
    
    # å¼€å§‹è®­ç»ƒ
    trainer.train(
        train_loader=train_loader,
        val_loader=val_loader,
        epochs=config['epochs'],
        base_lr=config['base_lr'],
        backbone_lr_ratio=config['backbone_lr_ratio'],
        weight_decay=config['weight_decay'],
        freeze_backbone_epochs=config['freeze_backbone_epochs']
    )


if __name__ == "__main__":
    main()
