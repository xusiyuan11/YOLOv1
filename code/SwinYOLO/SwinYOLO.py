"""
SwinYOLO: åŸºäºSwin Transformerçš„ç®€åŒ–YOLOæ£€æµ‹å™¨
ç›´æ¥åœ¨Swinåé¢æ¥æ£€æµ‹å¤´ï¼Œæ¶æ„æ›´æ¸…æ™°
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from backbone import create_backbone


class SwinYOLODetector(nn.Module):
    """
    åŸºäºSwin Transformerçš„YOLOæ£€æµ‹å™¨
    ç®€åŒ–æ¶æ„ï¼šSwin Backbone + æ£€æµ‹å¤´
    """
    
    def __init__(self, 
                 num_classes=20, 
                 input_size=448, 
                 grid_size=7,
                 num_boxes=2):
        super(SwinYOLODetector, self).__init__()
        
        self.num_classes = num_classes
        self.input_size = input_size
        self.grid_size = grid_size
        self.num_boxes = num_boxes
        
        # Swin Transformer backbone
        self.backbone = create_backbone('swin', input_size=input_size)
        
        # æ£€æµ‹å¤´ï¼šå°†Swinçš„512ç»´ç‰¹å¾è½¬æ¢ä¸ºYOLOè¾“å‡º
        # è¾“å‡ºé€šé“æ•°: num_boxes * 5 + num_classes
        # æ¯ä¸ªbox: (x, y, w, h, confidence) = 5ä¸ªå€¼
        output_channels = num_boxes * 5 + num_classes
        
        self.detection_head = nn.Sequential(
            # ç¬¬ä¸€å±‚ï¼šç‰¹å¾å¢å¼º
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.1, inplace=True),
            
            # ç¬¬äºŒå±‚ï¼šé™ç»´
            nn.Conv2d(512, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.1, inplace=True),
            
            # ç¬¬ä¸‰å±‚ï¼šè¾“å‡ºå±‚
            nn.Conv2d(256, output_channels, kernel_size=1),
        )
        
        # ğŸ”§ æ”¹è¿›æ£€æµ‹å¤´åˆå§‹åŒ–ï¼Œç‰¹åˆ«æ˜¯åˆ†ç±»å±‚çš„åç½®
        self._init_detection_head()
        
        # å¦‚æœSwinè¾“å‡º14x14ï¼Œéœ€è¦è°ƒæ•´åˆ°ç›®æ ‡grid_size
        self.need_resize = True  # Swinè¾“å‡º14x14ï¼Œé€šå¸¸éœ€è¦è°ƒæ•´
    
    def _init_detection_head(self):
        """åˆå§‹åŒ–æ£€æµ‹å¤´ï¼Œç‰¹åˆ«æ˜¯åˆ†ç±»å±‚çš„åç½®"""
        # è·å–æœ€åä¸€å±‚ï¼ˆè¾“å‡ºå±‚ï¼‰
        output_layer = self.detection_head[-1]
        
        # åˆå§‹åŒ–ç½®ä¿¡åº¦åç½®ä¸ºè´Ÿå€¼ï¼Œè®©æ¨¡å‹å¼€å§‹æ—¶æ›´è°¨æ…
        # åæ ‡å’Œå°ºå¯¸çš„åç½®ä¿æŒä¸º0
        with torch.no_grad():
            # ç½®ä¿¡åº¦åç½®è®¾ä¸º-2ï¼Œå¯¹åº”sigmoidåçº¦0.12çš„åˆå§‹ç½®ä¿¡åº¦
            output_layer.bias[self.num_boxes*4:self.num_boxes*5].fill_(-2.0)
            
            # åˆ†ç±»å±‚åç½®è®¾ä¸ºå°çš„éšæœºå€¼ï¼Œé¿å…å®Œå…¨åå‘æŸäº›ç±»åˆ«
            class_start_idx = self.num_boxes * 5
            output_layer.bias[class_start_idx:].normal_(0, 0.01)
        
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­
        Args:
            x: è¾“å…¥å›¾åƒ [B, 3, 448, 448]
        Returns:
            output: YOLOè¾“å‡º [B, grid_size, grid_size, num_boxes*5 + num_classes]
        """
        # Swin backboneæå–ç‰¹å¾
        features = self.backbone(x)  # [B, 512, 14, 14]
        
        # è°ƒæ•´ç‰¹å¾å›¾å°ºå¯¸åˆ°ç›®æ ‡grid_size
        if self.need_resize and features.shape[-1] != self.grid_size:
            features = F.adaptive_avg_pool2d(features, (self.grid_size, self.grid_size))
        
        # æ£€æµ‹å¤´å¤„ç†
        detection_output = self.detection_head(features)  # [B, output_channels, grid_size, grid_size]
        
        # è½¬æ¢ç»´åº¦é¡ºåº: [B, C, H, W] -> [B, H, W, C]
        detection_output = detection_output.permute(0, 2, 3, 1)  # [B, grid_size, grid_size, output_channels]
        
        return detection_output
    
    def freeze_backbone(self):
        """å†»ç»“backboneï¼Œåªè®­ç»ƒæ£€æµ‹å¤´"""
        for param in self.backbone.parameters():
            param.requires_grad = False
        print("âœ… Swin backboneå·²å†»ç»“ï¼Œåªè®­ç»ƒæ£€æµ‹å¤´")
    
    def unfreeze_backbone(self):
        """è§£å†»backboneï¼Œè¿›è¡Œç«¯åˆ°ç«¯å¾®è°ƒ"""
        for param in self.backbone.parameters():
            param.requires_grad = True
        print("âœ… Swin backboneå·²è§£å†»ï¼Œè¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒ")
    
    def get_parameter_groups(self, base_lr=0.001, backbone_lr_ratio=0.1):
        """
        è·å–ä¸åŒå­¦ä¹ ç‡çš„å‚æ•°ç»„
        backboneä½¿ç”¨è¾ƒå°çš„å­¦ä¹ ç‡ï¼Œæ£€æµ‹å¤´ä½¿ç”¨è¾ƒå¤§çš„å­¦ä¹ ç‡
        """
        backbone_params = []
        detection_params = []
        
        for name, param in self.named_parameters():
            if param.requires_grad:
                if 'backbone' in name:
                    backbone_params.append(param)
                else:
                    detection_params.append(param)
        
        param_groups = []
        if backbone_params:
            param_groups.append({
                'params': backbone_params,
                'lr': base_lr * backbone_lr_ratio,
                'name': 'swin_backbone'
            })
        if detection_params:
            param_groups.append({
                'params': detection_params,
                'lr': base_lr,
                'name': 'detection_head'
            })
        
        return param_groups
    
    def load_pretrained_backbone(self, pretrained_path):
        """
        åŠ è½½é¢„è®­ç»ƒçš„åˆ†ç±»æ¨¡å‹ä¸­çš„backboneæƒé‡
        """
        try:
            checkpoint = torch.load(pretrained_path, map_location='cpu', weights_only=False)
            
            # å°è¯•ä¸åŒçš„é”®å
            if 'model_state_dict' in checkpoint:
                state_dict = checkpoint['model_state_dict']
            elif 'backbone_state_dict' in checkpoint:
                state_dict = checkpoint['backbone_state_dict']
            else:
                state_dict = checkpoint
            
            # æå–backboneç›¸å…³æƒé‡
            backbone_state_dict = {}
            for key, value in state_dict.items():
                if 'backbone' in key:
                    # å»æ‰å‰ç¼€
                    new_key = key.replace('model.backbone.', '').replace('backbone.', '')
                    backbone_state_dict[new_key] = value
            
            # åŠ è½½æƒé‡
            missing_keys, unexpected_keys = self.backbone.load_state_dict(backbone_state_dict, strict=False)
            
            print(f"âœ… æˆåŠŸåŠ è½½é¢„è®­ç»ƒbackbone")
            print(f"   åŠ è½½å±‚æ•°: {len(backbone_state_dict) - len(missing_keys)}")
            if missing_keys:
                print(f"   æœªåŒ¹é…å±‚æ•°: {len(missing_keys)}")
                
        except Exception as e:
            print(f"âŒ åŠ è½½é¢„è®­ç»ƒbackboneå¤±è´¥: {e}")
            print("   å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–ç»§ç»­è®­ç»ƒ")


class SwinYOLOLoss(nn.Module):
    """
    ç®€åŒ–çš„YOLOæŸå¤±å‡½æ•°ï¼Œé€‚é…SwinYOLO
    """
    
    def __init__(self, 
                 num_classes=20, 
                 num_boxes=2,
                 lambda_coord=10.0,  # å¢åŠ åæ ‡æŸå¤±æƒé‡ (åº”ç”¨YOLOv1/v3ç»éªŒ)
                 lambda_noobj=0.1):  # å‡å°‘æ— ç›®æ ‡æŸå¤±æƒé‡ (åº”ç”¨ä¼˜åŒ–ç»éªŒ)
        super(SwinYOLOLoss, self).__init__()
        
        self.num_classes = num_classes
        self.num_boxes = num_boxes
        self.lambda_coord = lambda_coord
        self.lambda_noobj = lambda_noobj
        
    def forward(self, predictions, targets):
        """
        è®¡ç®—YOLOæŸå¤±
        Args:
            predictions: æ¨¡å‹é¢„æµ‹ [B, grid_size, grid_size, num_boxes*5 + num_classes]
            targets: çœŸå®æ ‡ç­¾ [B, grid_size, grid_size, num_boxes*5 + num_classes]
        """
        batch_size, grid_size, _, _ = predictions.shape
        
        # åˆ†ç¦»é¢„æµ‹çš„ä¸åŒéƒ¨åˆ†
        # è¾¹ç•Œæ¡†: [B, grid_size, grid_size, num_boxes*4]
        # ç½®ä¿¡åº¦: [B, grid_size, grid_size, num_boxes]  
        # ç±»åˆ«: [B, grid_size, grid_size, num_classes]
        
        pred_boxes = predictions[..., :self.num_boxes*4].view(batch_size, grid_size, grid_size, self.num_boxes, 4)
        pred_conf = predictions[..., self.num_boxes*4:self.num_boxes*5].view(batch_size, grid_size, grid_size, self.num_boxes)
        pred_classes = predictions[..., self.num_boxes*5:]
        
        target_boxes = targets[..., :self.num_boxes*4].view(batch_size, grid_size, grid_size, self.num_boxes, 4)
        target_conf = targets[..., self.num_boxes*4:self.num_boxes*5].view(batch_size, grid_size, grid_size, self.num_boxes)
        target_classes = targets[..., self.num_boxes*5:]
        
        # è®¡ç®—å„é¡¹æŸå¤±
        coord_loss = self._coordinate_loss(pred_boxes, target_boxes, target_conf)
        conf_loss = self._confidence_loss(pred_conf, target_conf)
        class_loss = self._classification_loss(pred_classes, target_classes, target_conf)
        
        # ğŸ”§ å¹³è¡¡æŸå¤±æƒé‡ï¼Œè§£å†³ç±»åˆ«é¢„æµ‹åå‘é—®é¢˜
        lambda_conf = 1.0   # é™ä½ç½®ä¿¡åº¦æŸå¤±æƒé‡
        lambda_class = 2.0  # å¢åŠ åˆ†ç±»æŸå¤±æƒé‡ï¼Œé¼“åŠ±å­¦ä¹ æ›´å¤šç±»åˆ«
        total_loss = (self.lambda_coord * coord_loss + 
                     lambda_conf * conf_loss + 
                     lambda_class * class_loss)
        
        return {
            'total_loss': total_loss,
            'coord_loss': coord_loss,
            'conf_loss': conf_loss, 
            'class_loss': class_loss
        }
    
    def _coordinate_loss(self, pred_boxes, target_boxes, target_conf):
        """åæ ‡æŸå¤±"""
        # åªè®¡ç®—æœ‰ç›®æ ‡çš„ç½‘æ ¼çš„åæ ‡æŸå¤±
        mask = target_conf > 0  # [B, grid_size, grid_size, num_boxes]
        
        if mask.sum() == 0:
            return torch.tensor(0.0, device=pred_boxes.device)
        
        # åæ ‡æŸå¤± (x, y, w, h)
        coord_loss = F.mse_loss(
            pred_boxes[mask], 
            target_boxes[mask], 
            reduction='sum'
        ) / mask.sum()
        
        return coord_loss
    
    def _confidence_loss(self, pred_conf, target_conf):
        """ç½®ä¿¡åº¦æŸå¤±"""
        # æœ‰ç›®æ ‡çš„ç½®ä¿¡åº¦æŸå¤±
        obj_mask = target_conf > 0
        obj_loss = F.mse_loss(pred_conf[obj_mask], target_conf[obj_mask], reduction='sum') if obj_mask.sum() > 0 else 0
        
        # æ— ç›®æ ‡çš„ç½®ä¿¡åº¦æŸå¤±
        noobj_mask = target_conf == 0
        noobj_loss = F.mse_loss(pred_conf[noobj_mask], target_conf[noobj_mask], reduction='sum') if noobj_mask.sum() > 0 else 0
        
        return obj_loss + self.lambda_noobj * noobj_loss
    
    def _classification_loss(self, pred_classes, target_classes, target_conf):
        """åˆ†ç±»æŸå¤± - å¢å¼ºç‰ˆï¼Œè§£å†³ç±»åˆ«é¢„æµ‹åå‘é—®é¢˜"""
        # åªè®¡ç®—æœ‰ç›®æ ‡çš„ç½‘æ ¼çš„åˆ†ç±»æŸå¤±
        mask = target_conf.max(dim=-1)[0] > 0  # [B, grid_size, grid_size]
        
        if mask.sum() == 0:
            return torch.tensor(0.0, device=pred_classes.device)
        
        # ä½¿ç”¨äº¤å‰ç†µæŸå¤±æ›¿ä»£MSEï¼Œæ›´é€‚åˆåˆ†ç±»ä»»åŠ¡
        pred_classes_masked = pred_classes[mask]  # [N, num_classes]
        target_classes_masked = target_classes[mask]  # [N, num_classes]
        
        # å°†one-hotç¼–ç è½¬æ¢ä¸ºç±»åˆ«ç´¢å¼•
        target_indices = torch.argmax(target_classes_masked, dim=-1)  # [N]
        
        # ä½¿ç”¨äº¤å‰ç†µæŸå¤±ï¼Œè‡ªåŠ¨å¤„ç†ç±»åˆ«å¹³è¡¡
        class_loss = F.cross_entropy(pred_classes_masked, target_indices, reduction='mean')
        
        return class_loss


def create_swin_yolo(num_classes=20, input_size=448, grid_size=7, num_boxes=2):
    """
    åˆ›å»ºSwinYOLOæ£€æµ‹å™¨
    
    Args:
        num_classes: ç±»åˆ«æ•°é‡
        input_size: è¾“å…¥å›¾åƒå°ºå¯¸
        grid_size: ç½‘æ ¼å°ºå¯¸
        num_boxes: æ¯ä¸ªç½‘æ ¼é¢„æµ‹çš„è¾¹ç•Œæ¡†æ•°é‡
    
    Returns:
        model: SwinYOLOæ£€æµ‹å™¨
        loss_fn: å¯¹åº”çš„æŸå¤±å‡½æ•°
    """
    model = SwinYOLODetector(
        num_classes=num_classes,
        input_size=input_size, 
        grid_size=grid_size,
        num_boxes=num_boxes
    )
    
    loss_fn = SwinYOLOLoss(
        num_classes=num_classes,
        num_boxes=num_boxes
    )
    
    return model, loss_fn


if __name__ == "__main__":
    print("ğŸš€ æµ‹è¯•SwinYOLOæ£€æµ‹å™¨")
    
    # åˆ›å»ºæ¨¡å‹
    model, loss_fn = create_swin_yolo(num_classes=20, input_size=448, grid_size=7)
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    x = torch.randn(2, 3, 448, 448)
    output = model(x)
    
    print(f"âœ… SwinYOLOæµ‹è¯•æˆåŠŸ!")
    print(f"   è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"   æœŸæœ›è¾“å‡º: [2, 7, 7, {2*5 + 20}]")
    
    # æµ‹è¯•å‚æ•°ç»„
    param_groups = model.get_parameter_groups()
    print(f"   å‚æ•°ç»„æ•°é‡: {len(param_groups)}")
    for i, group in enumerate(param_groups):
        print(f"     ç»„{i+1}: {group['name']}, å‚æ•°æ•°é‡: {len(group['params'])}, å­¦ä¹ ç‡: {group['lr']}")
    
    print(f"\nğŸ“Š æ¨¡å‹ç»Ÿè®¡:")
    total_params = sum(p.numel() for p in model.parameters())
    print(f"   æ€»å‚æ•°é‡: {total_params:,}")
    print(f"   æ¨¡å‹å¤§å°: {total_params * 4 / 1024 / 1024:.1f} MB")
