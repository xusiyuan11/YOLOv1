"""
SwinYOLOè¯„ä¼°æ¨¡å—
åŒ…å«mAPã€IoUã€NMSç­‰ç›®æ ‡æ£€æµ‹è¯„ä¼°æŒ‡æ ‡å’Œåå¤„ç†å‡½æ•°
"""

import torch
import torch.nn.functional as F
import numpy as np
from typing import List, Tuple, Dict, Optional
from collections import defaultdict


def box_iou(box1: torch.Tensor, box2: torch.Tensor) -> torch.Tensor:
    """
    è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„IoU
    
    Args:
        box1: [N, 4] (x1, y1, x2, y2)
        box2: [M, 4] (x1, y1, x2, y2)
    
    Returns:
        iou: [N, M] IoUçŸ©é˜µ
    """
    # è®¡ç®—äº¤é›†åŒºåŸŸ
    inter_x1 = torch.max(box1[:, None, 0], box2[:, 0])
    inter_y1 = torch.max(box1[:, None, 1], box2[:, 1])
    inter_x2 = torch.min(box1[:, None, 2], box2[:, 2])
    inter_y2 = torch.min(box1[:, None, 3], box2[:, 3])
    
    # è®¡ç®—äº¤é›†é¢ç§¯
    inter_w = torch.clamp(inter_x2 - inter_x1, min=0)
    inter_h = torch.clamp(inter_y2 - inter_y1, min=0)
    inter_area = inter_w * inter_h
    
    # è®¡ç®—å„è‡ªé¢ç§¯
    area1 = (box1[:, 2] - box1[:, 0]) * (box1[:, 3] - box1[:, 1])
    area2 = (box2[:, 2] - box2[:, 0]) * (box2[:, 3] - box2[:, 1])
    
    # è®¡ç®—å¹¶é›†é¢ç§¯
    union_area = area1[:, None] + area2 - inter_area
    
    # è®¡ç®—IoU
    iou = inter_area / (union_area + 1e-6)
    return iou


def nms(boxes: torch.Tensor, scores: torch.Tensor, iou_threshold: float = 0.5) -> torch.Tensor:
    """
    éæå¤§å€¼æŠ‘åˆ¶(NMS)
    
    Args:
        boxes: [N, 4] è¾¹ç•Œæ¡†åæ ‡ (x1, y1, x2, y2)
        scores: [N] ç½®ä¿¡åº¦åˆ†æ•°
        iou_threshold: IoUé˜ˆå€¼
    
    Returns:
        keep: ä¿ç•™çš„è¾¹ç•Œæ¡†ç´¢å¼•
    """
    if boxes.numel() == 0:
        return torch.empty((0,), dtype=torch.long, device=boxes.device)
    
    # æŒ‰ç½®ä¿¡åº¦æ’åº
    _, order = scores.sort(descending=True)
    
    keep = []
    while order.numel() > 0:
        # é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„æ¡†
        i = order[0]
        keep.append(i)
        
        if order.numel() == 1:
            break
        
        # è®¡ç®—ä¸å…¶ä»–æ¡†çš„IoU
        iou = box_iou(boxes[i:i+1], boxes[order[1:]])[0]
        
        # ä¿ç•™IoUå°äºé˜ˆå€¼çš„æ¡†
        mask = iou <= iou_threshold
        order = order[1:][mask]
    
    return torch.tensor(keep, dtype=torch.long, device=boxes.device)


def decode_predictions(predictions: torch.Tensor, 
                      grid_size: int = 7, 
                      num_boxes: int = 2, 
                      num_classes: int = 20,
                      conf_threshold: float = 0.01,
                      input_size: int = 448) -> List[Dict]:
    """
    è§£ç SwinYOLOé¢„æµ‹ç»“æœ
    
    Args:
        predictions: [B, grid_size, grid_size, num_boxes*5 + num_classes]
        grid_size: ç½‘æ ¼å¤§å°
        num_boxes: æ¯ä¸ªç½‘æ ¼çš„è¾¹ç•Œæ¡†æ•°é‡
        num_classes: ç±»åˆ«æ•°é‡
        conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        input_size: è¾“å…¥å›¾åƒå°ºå¯¸
    
    Returns:
        æ‰¹æ¬¡ä¸­æ¯ä¸ªå›¾åƒçš„æ£€æµ‹ç»“æœåˆ—è¡¨
    """
    batch_size = predictions.size(0)
    cell_size = input_size / grid_size
    
    batch_detections = []
    
    for b in range(batch_size):
        pred = predictions[b]  # [grid_size, grid_size, num_boxes*5 + num_classes]
        
        # åˆ†ç¦»é¢„æµ‹çš„ä¸åŒéƒ¨åˆ†
        boxes = pred[..., :num_boxes*4].view(grid_size, grid_size, num_boxes, 4)
        confs = torch.sigmoid(pred[..., num_boxes*4:num_boxes*5]).view(grid_size, grid_size, num_boxes)
        class_probs = torch.sigmoid(pred[..., num_boxes*5:])  # [grid_size, grid_size, num_classes]
        
        detections = []
        
        # ğŸš€ å‘é‡åŒ–ä¼˜åŒ– - é¿å…ä¸‰é‡å¾ªç¯å’Œé¢‘ç¹çš„.item()è°ƒç”¨
        # ğŸ” è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºç½®ä¿¡åº¦åˆ†å¸ƒ
        if b == 0:  # åªåœ¨ç¬¬ä¸€ä¸ªbatchæ˜¾ç¤ºä¸€æ¬¡
            conf_values = confs.flatten()
            max_conf = torch.max(conf_values).item()
            mean_conf = torch.mean(conf_values).item()
            conf_above_001 = (conf_values > 0.001).sum().item()
            conf_above_01 = (conf_values > 0.01).sum().item()
            conf_above_1 = (conf_values > 0.1).sum().item()
            
            if max_conf < 0.1:  # å¦‚æœæœ€å¤§ç½®ä¿¡åº¦éƒ½å¾ˆä½ï¼Œè¾“å‡ºè­¦å‘Š
                print(f"   ğŸ” ç½®ä¿¡åº¦ç»Ÿè®¡: max={max_conf:.4f}, mean={mean_conf:.4f}")
                print(f"   ğŸ” ç½®ä¿¡åº¦åˆ†å¸ƒ: >0.001({conf_above_001}), >0.01({conf_above_01}), >0.1({conf_above_1})")
        
        # æ‰¾åˆ°æ‰€æœ‰æ»¡è¶³ç½®ä¿¡åº¦é˜ˆå€¼çš„æ¡†
        conf_mask = confs >= conf_threshold  # [grid_size, grid_size, num_boxes]
        
        if conf_mask.any():
            # è·å–æ»¡è¶³æ¡ä»¶çš„ç´¢å¼•
            valid_indices = torch.where(conf_mask)
            i_indices, j_indices, k_indices = valid_indices
            
            # æ‰¹é‡å¤„ç†æ‰€æœ‰æœ‰æ•ˆæ¡†
            valid_boxes = boxes[i_indices, j_indices, k_indices]  # [N, 4]
            valid_confs = confs[i_indices, j_indices, k_indices]  # [N]
            
            # æ‰¹é‡è®¡ç®—åæ ‡ï¼ˆYOLOæ ‡å‡†æ ¼å¼ï¼‰
            center_x = (j_indices.float() + valid_boxes[:, 0]) / grid_size  # å½’ä¸€åŒ–åˆ°[0,1]
            center_y = (i_indices.float() + valid_boxes[:, 1]) / grid_size  # å½’ä¸€åŒ–åˆ°[0,1]
            width = valid_boxes[:, 2]  # å·²ç»æ˜¯å½’ä¸€åŒ–å€¼
            height = valid_boxes[:, 3]  # å·²ç»æ˜¯å½’ä¸€åŒ–å€¼
            
            # è½¬æ¢ä¸º(x1, y1, x2, y2)æ ¼å¼
            x1 = center_x - width / 2
            y1 = center_y - height / 2
            x2 = center_x + width / 2
            y2 = center_y + height / 2
            
            # é™åˆ¶åœ¨å½’ä¸€åŒ–èŒƒå›´å†…[0,1]
            x1 = torch.clamp(x1, 0, 1)
            y1 = torch.clamp(y1, 0, 1)
            x2 = torch.clamp(x2, 0, 1)
            y2 = torch.clamp(y2, 0, 1)
            
            # æ‰¹é‡å¤„ç†ç±»åˆ«æ¦‚ç‡
            valid_class_probs = class_probs[i_indices, j_indices]  # [N, num_classes]
            class_scores = valid_class_probs * valid_confs.unsqueeze(1)  # [N, num_classes]
            max_class_scores, class_indices = torch.max(class_scores, dim=1)  # [N]
            
            # ç­›é€‰æ»¡è¶³é˜ˆå€¼çš„æ£€æµ‹ç»“æœ
            score_mask = max_class_scores > conf_threshold
            if score_mask.any():
                # åªåœ¨æœ€åè¿›è¡Œä¸€æ¬¡CPUè½¬æ¢ï¼Œå¤§å¹…å‡å°‘GPU-CPUä¼ è¾“
                final_boxes = torch.stack([x1, y1, x2, y2], dim=1)[score_mask].cpu().numpy()
                final_scores = max_class_scores[score_mask].cpu().numpy()
                final_classes = class_indices[score_mask].cpu().numpy()
                
                # æ‰¹é‡æ·»åŠ æ£€æµ‹ç»“æœ
                for i in range(len(final_boxes)):
                    detections.append({
                        'bbox': final_boxes[i].tolist(),
                        'score': float(final_scores[i]),
                        'class_id': int(final_classes[i])
                    })
        
        batch_detections.append(detections)
    
    return batch_detections


def apply_nms_to_detections(detections: List[Dict], 
                           iou_threshold: float = 0.5) -> List[Dict]:
    """
    å¯¹æ£€æµ‹ç»“æœåº”ç”¨NMS
    
    Args:
        detections: æ£€æµ‹ç»“æœåˆ—è¡¨
        iou_threshold: IoUé˜ˆå€¼
    
    Returns:
        ç»è¿‡NMSå¤„ç†çš„æ£€æµ‹ç»“æœ
    """
    if not detections:
        return []
    
    # æŒ‰ç±»åˆ«åˆ†ç»„
    class_detections = defaultdict(list)
    for det in detections:
        class_detections[det['class_id']].append(det)
    
    nms_detections = []
    
    # å¯¹æ¯ä¸ªç±»åˆ«åˆ†åˆ«åº”ç”¨NMS
    for class_id, class_dets in class_detections.items():
        if not class_dets:
            continue
        
        boxes = torch.tensor([det['bbox'] for det in class_dets])
        scores = torch.tensor([det['score'] for det in class_dets])
        
        keep_indices = nms(boxes, scores, iou_threshold)
        
        for idx in keep_indices:
            nms_detections.append(class_dets[idx])
    
    return nms_detections


def compute_ap(detections: List[Dict], 
               ground_truths: List[Dict], 
               class_id: int,
               iou_threshold: float = 0.5) -> float:
    """
    è®¡ç®—å•ä¸ªç±»åˆ«çš„Average Precision
    
    Args:
        detections: æ£€æµ‹ç»“æœ
        ground_truths: çœŸå®æ ‡æ³¨
        class_id: ç±»åˆ«ID
        iou_threshold: IoUé˜ˆå€¼
    
    Returns:
        APå€¼
    """
    # ç­›é€‰ç‰¹å®šç±»åˆ«çš„æ£€æµ‹ç»“æœå’ŒçœŸå®æ ‡æ³¨
    class_dets = [det for det in detections if det['class_id'] == class_id]
    class_gts = [gt for gt in ground_truths if gt['class_id'] == class_id]
    
    if not class_gts:
        return 0.0
    
    if not class_dets:
        return 0.0
    
    # æŒ‰ç½®ä¿¡åº¦æ’åº
    class_dets.sort(key=lambda x: x['score'], reverse=True)
    
    # è®¡ç®—TPå’ŒFP
    tp = []
    fp = []
    gt_matched = [False] * len(class_gts)
    
    for det in class_dets:
        det_box = torch.tensor(det['bbox']).unsqueeze(0)
        
        best_iou = 0
        best_gt_idx = -1
        
        for gt_idx, gt in enumerate(class_gts):
            if gt_matched[gt_idx]:
                continue
            
            gt_box = torch.tensor(gt['bbox']).unsqueeze(0)
            iou = box_iou(det_box, gt_box)[0, 0].item()
            
            if iou > best_iou:
                best_iou = iou
                best_gt_idx = gt_idx
        
        if best_iou >= iou_threshold:
            tp.append(1)
            fp.append(0)
            gt_matched[best_gt_idx] = True
        else:
            tp.append(0)
            fp.append(1)
    
    # è®¡ç®—precisionå’Œrecall
    tp = np.array(tp)
    fp = np.array(fp)
    
    tp_cumsum = np.cumsum(tp)
    fp_cumsum = np.cumsum(fp)
    
    recalls = tp_cumsum / len(class_gts)
    precisions = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-6)
    
    # è®¡ç®—AP (11ç‚¹æ’å€¼æ³•)
    ap = 0
    for t in np.arange(0, 1.1, 0.1):
        mask = recalls >= t
        if mask.any():
            ap += np.max(precisions[mask])
    ap /= 11
    
    return ap


def compute_map(all_detections: List[List[Dict]], 
                all_ground_truths: List[List[Dict]], 
                num_classes: int = 20,
                iou_threshold: float = 0.5) -> Dict[str, float]:
    """
    è®¡ç®—mAP
    
    Args:
        all_detections: æ‰€æœ‰å›¾åƒçš„æ£€æµ‹ç»“æœ
        all_ground_truths: æ‰€æœ‰å›¾åƒçš„çœŸå®æ ‡æ³¨
        num_classes: ç±»åˆ«æ•°é‡
        iou_threshold: IoUé˜ˆå€¼
    
    Returns:
        åŒ…å«å„ç±»åˆ«APå’ŒmAPçš„å­—å…¸
    """
    # åˆå¹¶æ‰€æœ‰æ£€æµ‹ç»“æœå’ŒçœŸå®æ ‡æ³¨
    combined_detections = []
    combined_ground_truths = []
    
    for img_dets, img_gts in zip(all_detections, all_ground_truths):
        combined_detections.extend(img_dets)
        combined_ground_truths.extend(img_gts)
    
    # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„AP
    aps = []
    class_aps = {}
    
    for class_id in range(num_classes):
        ap = compute_ap(combined_detections, combined_ground_truths, class_id, iou_threshold)
        aps.append(ap)
        class_aps[f'class_{class_id}'] = ap
    
    # è®¡ç®—mAP
    map_score = np.mean(aps)
    
    result = {
        'mAP': map_score,
        **class_aps
    }
    
    return result


def evaluate_model(model, dataloader, device, num_classes=20, conf_threshold=0.01, iou_threshold=0.5):
    """
    è¯„ä¼°æ¨¡å‹æ€§èƒ½
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        dataloader: éªŒè¯æ•°æ®åŠ è½½å™¨
        device: è®¾å¤‡
        num_classes: ç±»åˆ«æ•°é‡
        conf_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        iou_threshold: IoUé˜ˆå€¼
    
    Returns:
        è¯„ä¼°ç»“æœå­—å…¸
    """
    model.eval()
    
    all_detections = []
    all_ground_truths = []
    
    with torch.no_grad():
        for images, targets in dataloader:
            images = images.to(device)
            
            # æ¨¡å‹é¢„æµ‹
            predictions = model(images)
            
            # è§£ç é¢„æµ‹ç»“æœ
            batch_detections = decode_predictions(
                predictions, 
                conf_threshold=conf_threshold
            )
            
            # å¯¹æ¯ä¸ªæ£€æµ‹ç»“æœåº”ç”¨NMS
            for detections in batch_detections:
                nms_detections = apply_nms_to_detections(detections, iou_threshold)
                all_detections.append(nms_detections)
            
            # å¤„ç†çœŸå®æ ‡æ³¨ï¼ˆSwinYOLOæ•°æ®æ ¼å¼ï¼‰
            # targetsæ˜¯åˆ—è¡¨ï¼š[[gt1, mask_pos1, mask_neg1], [gt2, mask_pos2, mask_neg2], ...]
            # æˆ‘ä»¬éœ€è¦æå–æ‰€æœ‰çš„gtï¼š[gt1, gt2, gt3, ...]
            try:
                if isinstance(targets, list) and len(targets) > 0:
                    gt_list = []
                    for sample_targets in targets:
                        if isinstance(sample_targets, list) and len(sample_targets) >= 1:
                            gt_list.append(sample_targets[0])  # æå–æ¯ä¸ªæ ·æœ¬çš„gt
                        else:
                            print(f"Warning: æ ·æœ¬targetsæ ¼å¼ä¸æ­£ç¡®ï¼Œè·³è¿‡")
                            continue
                    
                    if len(gt_list) > 0:
                        # å †å æ‰€æœ‰gt tensor
                        gt_targets = torch.stack(gt_list)
                    else:
                        print(f"Warning: æ²¡æœ‰æœ‰æ•ˆçš„gtæ•°æ®ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡çš„mAPè®¡ç®—")
                        continue
                else:
                    # å¦‚æœtargetsä¸æ˜¯åˆ—è¡¨æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                    gt_targets = targets
            except Exception as e:
                print(f"Warning: å¤„ç†gt_targetsæ—¶å‡ºé”™({e})ï¼Œè·³è¿‡æ­¤æ‰¹æ¬¡çš„mAPè®¡ç®—")
                continue
            
            # è§£ç çœŸå®æ ‡æ³¨ä¸ºæ£€æµ‹æ ¼å¼
            batch_ground_truths = decode_ground_truths(gt_targets)
            all_ground_truths.extend(batch_ground_truths)
    
    # ğŸ” ç»Ÿè®¡é¢„æµ‹å’ŒçœŸå®æ ‡ç­¾çš„ç±»åˆ«åˆ†å¸ƒ (ç”¨äºè°ƒè¯•)
    from collections import Counter
    pred_class_counts = Counter()
    gt_class_counts = Counter()
    
    for detections in all_detections:
        for det in detections:
            pred_class_counts[det['class_id']] += 1
    
    for ground_truths in all_ground_truths:
        for gt in ground_truths:
            gt_class_counts[gt['class_id']] += 1
    
    print(f"   é¢„æµ‹ç±»åˆ«ç»Ÿè®¡: {len(pred_class_counts)}/20ä¸ªç±»åˆ«è¢«é¢„æµ‹")
    print(f"   çœŸå®ç±»åˆ«ç»Ÿè®¡: {len(gt_class_counts)}/20ä¸ªç±»åˆ«å­˜åœ¨")
    
    if len(pred_class_counts) < 5:
        print(f"   âš ï¸  é¢„æµ‹ç±»åˆ«è¿‡å°‘! åªé¢„æµ‹äº†{len(pred_class_counts)}ä¸ªç±»åˆ«")
        print(f"   é¢„æµ‹åˆ†å¸ƒ: {dict(pred_class_counts.most_common(5))}")
    
    if len(gt_class_counts) < 5:
        print(f"   âš ï¸  çœŸå®ç±»åˆ«è¿‡å°‘! åªæœ‰{len(gt_class_counts)}ä¸ªç±»åˆ«")
        print(f"   çœŸå®åˆ†å¸ƒ: {dict(gt_class_counts.most_common(5))}")
    
    # è®¡ç®—mAP
    map_results = compute_map(all_detections, all_ground_truths, num_classes, iou_threshold)
    
    return map_results


def decode_ground_truths(gt_targets, 
                        grid_size: int = 7, 
                        num_boxes: int = 2, 
                        num_classes: int = 20,
                        input_size: int = 448) -> List[List[Dict]]:
    """
    è§£ç çœŸå®æ ‡æ³¨ä¸ºè¯„ä¼°æ ¼å¼
    
    Args:
        gt_targets: [B, grid_size, grid_size, num_boxes*5 + num_classes] æˆ– list
        grid_size: ç½‘æ ¼å¤§å°
        num_boxes: æ¯ä¸ªç½‘æ ¼çš„è¾¹ç•Œæ¡†æ•°é‡
        num_classes: ç±»åˆ«æ•°é‡
        input_size: è¾“å…¥å›¾åƒå°ºå¯¸
    
    Returns:
        æ‰¹æ¬¡ä¸­æ¯ä¸ªå›¾åƒçš„çœŸå®æ ‡æ³¨åˆ—è¡¨
    """
    # å¤„ç†ä¸åŒçš„è¾“å…¥æ ¼å¼
    if isinstance(gt_targets, list):
        if len(gt_targets) == 0:
            return []
        # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œè½¬æ¢ä¸ºtensor
        if isinstance(gt_targets[0], torch.Tensor):
            gt_targets = torch.stack(gt_targets)
        else:
            # å¦‚æœåˆ—è¡¨ä¸­çš„å…ƒç´ ä¸æ˜¯tensorï¼Œè¿”å›ç©ºç»“æœ
            return [[] for _ in range(len(gt_targets))]
    
    if not isinstance(gt_targets, torch.Tensor):
        return []
        
    batch_size = gt_targets.size(0)
    cell_size = input_size / grid_size
    
    batch_ground_truths = []
    
    for b in range(batch_size):
        gt = gt_targets[b]  # [grid_size, grid_size, num_boxes*5 + num_classes]
        
        # åˆ†ç¦»ä¸åŒéƒ¨åˆ†
        boxes = gt[..., :num_boxes*4].view(grid_size, grid_size, num_boxes, 4)
        confs = gt[..., num_boxes*4:num_boxes*5].view(grid_size, grid_size, num_boxes)
        class_probs = gt[..., num_boxes*5:]  # [grid_size, grid_size, num_classes]
        
        ground_truths = []
        
        for i in range(grid_size):
            for j in range(grid_size):
                # æ£€æŸ¥æ˜¯å¦æœ‰ç›®æ ‡
                if confs[i, j].max().item() > 0:
                    # æ‰¾åˆ°ç½®ä¿¡åº¦æœ€é«˜çš„è¾¹ç•Œæ¡†
                    best_box_idx = torch.argmax(confs[i, j]).item()
                    
                    # è§£ç è¾¹ç•Œæ¡†åæ ‡ï¼ˆYOLOæ ‡å‡†æ ¼å¼ï¼‰
                    x = (j + boxes[i, j, best_box_idx, 0].item()) / grid_size  # å½’ä¸€åŒ–åˆ°[0,1]
                    y = (i + boxes[i, j, best_box_idx, 1].item()) / grid_size  # å½’ä¸€åŒ–åˆ°[0,1]
                    w = boxes[i, j, best_box_idx, 2].item()  # å·²ç»æ˜¯å½’ä¸€åŒ–å€¼
                    h = boxes[i, j, best_box_idx, 3].item()  # å·²ç»æ˜¯å½’ä¸€åŒ–å€¼
                    
                    # è½¬æ¢ä¸º(x1, y1, x2, y2)æ ¼å¼
                    x1 = x - w / 2
                    y1 = y - h / 2
                    x2 = x + w / 2
                    y2 = y + h / 2
                    
                    # é™åˆ¶åœ¨å½’ä¸€åŒ–èŒƒå›´å†…[0,1]
                    x1 = max(0, min(x1, 1))
                    y1 = max(0, min(y1, 1))
                    x2 = max(0, min(x2, 1))
                    y2 = max(0, min(y2, 1))
                    
                    # è·å–ç±»åˆ«ID
                    class_id = torch.argmax(class_probs[i, j]).item()
                    
                    ground_truths.append({
                        'bbox': [x1, y1, x2, y2],
                        'class_id': class_id
                    })
        
        batch_ground_truths.append(ground_truths)
    
    return batch_ground_truths
