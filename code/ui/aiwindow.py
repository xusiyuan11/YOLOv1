# -*- coding: UTF-8 -*-
"""
è‡ªåŠ¨é©¾é©¶ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ - ä¸»çª—å£ç±»
"""
import sys
import os
from PyQt5.QtWidgets import QMainWindow, QFileDialog
from PyQt5.QtCore import Qt
from aiui import AutonomousDrivingUISetup
from aicamera import CameraVideoHandler
from PIL import Image
import torchvision.transforms as transforms
import torch
import cv2
from PyQt5.QtGui import QPixmap, QImage


class AutonomousDrivingUI(QMainWindow, AutonomousDrivingUISetup, CameraVideoHandler):
    """è‡ªåŠ¨é©¾é©¶ç›®æ ‡æ£€æµ‹ç³»ç»Ÿä¸»çª—å£"""

    def __init__(self):
        super().__init__()
        # åˆå§‹åŒ–UI
        self.setup_ui()
        # åˆå§‹åŒ–æ‘„åƒå¤´å’Œè§†é¢‘å¤„ç†
        self.setup_camera_video()

        # åŠ è½½æ¨¡å‹
        self.model = self.load_model()

        # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
        self.recent_detections = []  # å­˜å‚¨æœ€è¿‘æ£€æµ‹ç»“æœ
        self.reset_stats()

    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.update_detection_info(0, 0, 0, 0, {})

    def update_detection_info(self, targets, inference_time, fps, progress, class_counts, status="å¾…æœºä¸­"):
        """æ›´æ–°æ£€æµ‹ä¿¡æ¯æ˜¾ç¤º"""
        # é»˜è®¤ç±»åˆ«ç»Ÿè®¡
        default_classes = {
            "è½¦è¾†": 0, "è¡Œäºº": 0, "äº¤é€šç¯": 0, "æ ‡å¿—ç‰Œ": 0,
            "å…¬äº¤è½¦": 0, "å¡è½¦": 0, "æ‘©æ‰˜è½¦": 0, "è‡ªè¡Œè½¦": 0
        }
        
        # åˆå¹¶å®é™…æ£€æµ‹ç»“æœ
        for class_name, count in class_counts.items():
            if class_name in default_classes:
                default_classes[class_name] = count
        
        # æ„å»ºæ£€æµ‹ä¿¡æ¯æ–‡æœ¬
        info_text = f"""
ğŸ” è‡ªåŠ¨é©¾é©¶ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ v2.0
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š ç³»ç»ŸçŠ¶æ€: {status}
ğŸ¯ æ£€æµ‹ç›®æ ‡: {targets} ä¸ª
â±ï¸ æ¨ç†æ—¶é—´: {inference_time} ms
ğŸ“ˆ å¤„ç†å¸§ç‡: {fps} FPS
ğŸ“¶ å¤„ç†è¿›åº¦: {progress}%

ğŸ·ï¸ æ£€æµ‹ç±»åˆ«ç»Ÿè®¡:
   ğŸš— è½¦è¾†: {default_classes["è½¦è¾†"]}
   ğŸš¶ è¡Œäºº: {default_classes["è¡Œäºº"]}
   ğŸš¦ äº¤é€šç¯: {default_classes["äº¤é€šç¯"]}
   ğŸš§ æ ‡å¿—ç‰Œ: {default_classes["æ ‡å¿—ç‰Œ"]}
   ğŸšŒ å…¬äº¤è½¦: {default_classes["å…¬äº¤è½¦"]}
   ğŸš› å¡è½¦: {default_classes["å¡è½¦"]}
   ğŸï¸ æ‘©æ‰˜è½¦: {default_classes["æ‘©æ‰˜è½¦"]}
   ğŸš² è‡ªè¡Œè½¦: {default_classes["è‡ªè¡Œè½¦"]}

ğŸ“‹ æœ€è¿‘æ£€æµ‹ç»“æœ:
   {self.get_recent_detections()}

ğŸ’¡ ç³»ç»Ÿæç¤º:
   {self.get_system_tip(status)}
        """
        
        self.detection_info.setPlainText(info_text.strip())

    def get_recent_detections(self):
        """è·å–æœ€è¿‘æ£€æµ‹ç»“æœ"""
        if hasattr(self, 'recent_detections') and self.recent_detections:
            return "\n   ".join(self.recent_detections[-3:])  # æ˜¾ç¤ºæœ€è¿‘3æ¡
        return "æš‚æ— æ£€æµ‹æ•°æ®"

    def get_system_tip(self, status):
        """è·å–ç³»ç»Ÿæç¤º"""
        tips = {
            "å¾…æœºä¸­": "è¯·é€‰æ‹©è¾“å…¥æºå¼€å§‹æ£€æµ‹",
            "æ£€æµ‹ä¸­": "æ­£åœ¨å¤„ç†è¾“å…¥æ•°æ®ï¼Œè¯·ç¨å€™...",
            "å®Œæˆ": "æ£€æµ‹å®Œæˆï¼Œå¯æŸ¥çœ‹ç»“æœ",
            "é”™è¯¯": "æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥è¾“å…¥"
        }
        return tips.get(status, "ç³»ç»Ÿè¿è¡Œæ­£å¸¸")

    def connect_signals(self):
        """è¿æ¥æ‰€æœ‰ä¿¡å·å’Œæ§½å‡½æ•°"""
        # å‚æ•°æ§åˆ¶ä¿¡å· - ç°åœ¨é€šè¿‡æŒ‰é’®å¼¹çª—å¤„ç†ï¼Œä¸éœ€è¦ç›´æ¥è¿æ¥
        # self.conf_spin.valueChanged.connect(self.on_conf_changed)
        # self.conf_slider.valueChanged.connect(self.on_conf_slider_changed)
        # self.iou_spin.valueChanged.connect(self.on_iou_changed)
        # self.iou_slider.valueChanged.connect(self.on_iou_slider_changed)

        # è¾“å…¥æºé€‰æ‹©ä¿¡å·
        self.btn_image.clicked.connect(self.on_image_clicked)
        self.btn_video.clicked.connect(self.on_video_clicked)
        self.btn_camera.clicked.connect(self.on_camera_clicked)

        # æ§åˆ¶ä¿¡å·
        self.btn_play.clicked.connect(self.on_play_clicked)
        self.btn_stop.clicked.connect(self.on_stop_clicked)

    # å‚æ•°è°ƒæ•´å›è°ƒå‡½æ•°
    def on_conf_changed(self, value):
        """Confidenceå€¼æ”¹å˜"""
        self.conf_slider.setValue(int(value * 100))
        self.console.append(f"ğŸ¯ Confidenceé˜ˆå€¼è°ƒæ•´ä¸º: {value:.2f}")

    def on_conf_slider_changed(self, value):
        """Confidenceæ»‘å—æ”¹å˜"""
        self.conf_spin.setValue(value / 100.0)

    def on_iou_changed(self, value):
        """IOUå€¼æ”¹å˜"""
        self.iou_slider.setValue(int(value * 100))
        self.console.append(f"ğŸ“ IOUé˜ˆå€¼è°ƒæ•´ä¸º: {value:.2f}")

    def on_iou_slider_changed(self, value):
        """IOUæ»‘å—æ”¹å˜"""
        self.iou_spin.setValue(value / 100.0)

    def load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        model_path = 'model.pth'
        if not os.path.exists(model_path):
            self.console.append("âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡åŠ è½½")
            return None

        try:
            model = torch.load(model_path)
            model.eval()
            self.console.append("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            return model
        except Exception as e:
            self.console.append(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            return None

    def detect_image(self, image_path):
        """æ£€æµ‹å›¾åƒå¹¶æ˜¾ç¤ºç»“æœ"""
        # é¦–å…ˆæ˜¾ç¤ºå›¾åƒ
        if not self.display_image(image_path):
            return

        if self.model is None:
            self.console.append("âš ï¸ æœªåŠ è½½æ¨¡å‹ï¼Œæ— æ³•è¿›è¡Œæ£€æµ‹")
            return

        try:
            # åŠ è½½å›¾åƒ
            image = Image.open(image_path).convert('RGB')

            # å›¾åƒé¢„å¤„ç†
            transform = transforms.Compose([
                transforms.Resize((640, 640)),
                transforms.ToTensor(),
            ])
            input_tensor = transform(image).unsqueeze(0)

            # æ¨¡å‹æ¨ç†
            with torch.no_grad():
                outputs = self.model(input_tensor)

            # å¤„ç†æ£€æµ‹ç»“æœ
            self.process_detection_results(outputs)

            self.console.append("âœ… å›¾åƒæ£€æµ‹å®Œæˆ")

        except Exception as e:
            self.console.append(f"âŒ å›¾åƒæ£€æµ‹å¤±è´¥: {str(e)}")

    def process_detection_results(self, outputs):
        """å¤„ç†æ£€æµ‹ç»“æœå¹¶æ˜¾ç¤º"""
        # è¿™é‡Œåº”è¯¥æ ¹æ®å®é™…çš„æ¨¡å‹è¾“å‡ºæ ¼å¼æ¥è§£ææ£€æµ‹ç»“æœ
        # ç”±äºä¸çŸ¥é“å…·ä½“æ¨¡å‹ç»“æ„ï¼Œè¿™é‡Œåªæ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        self.update_detection_info(0, 0, 0, 50, {}, status="æ£€æµ‹ä¸­...")

        # æ¨¡æ‹Ÿå¤„ç†å®Œæˆ
        self.console.append("ğŸ” æ­£åœ¨åˆ†ææ£€æµ‹ç»“æœ...")

    # è¾“å…¥æºé€‰æ‹©å›è°ƒå‡½æ•°
    def on_image_clicked(self):
        """å›¾åƒæ£€æµ‹æŒ‰é’®ç‚¹å‡»"""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©å›¾åƒæ–‡ä»¶", "", "å›¾åƒæ–‡ä»¶ (*.png *.jpg *.jpeg *.bmp)"
        )
        if file_path:
            self.stop_all()  # åœæ­¢å…¶ä»–æ¨¡å¼
            self.current_image_path = file_path
            self.console.append(f"ğŸ–¼ï¸ å·²é€‰æ‹©å›¾åƒ: {os.path.basename(file_path)}")
            # æ˜¾ç¤ºå›¾åƒå¹¶è¿›è¡Œæ£€æµ‹
            self.detect_image(file_path)

    def on_video_clicked(self):
        """è§†é¢‘æ£€æµ‹æŒ‰é’®ç‚¹å‡»"""
        file_path, _ = QFileDialog.getOpenFileName(
            self, "é€‰æ‹©è§†é¢‘æ–‡ä»¶", "", "è§†é¢‘æ–‡ä»¶ (*.mp4 *.avi *.mov *.mkv)"
        )
        if file_path:
            self.stop_all()  # åœæ­¢å…¶ä»–æ¨¡å¼
            self.console.append(f"ğŸ¬ å·²é€‰æ‹©è§†é¢‘: {os.path.basename(file_path)}")
            self.start_video_playback(file_path)

    def on_camera_clicked(self):
        """æ‘„åƒå¤´æŒ‰é’®ç‚¹å‡»"""
        if not self.camera_running:
            # åœæ­¢å…¶ä»–æ¨¡å¼
            self.stop_video_playback()

            # å°è¯•å¯åŠ¨çœŸå®æ‘„åƒå¤´
            if self.start_camera():
                self.console.append("ğŸ“¹ å¯åŠ¨çœŸå®æ‘„åƒå¤´æ£€æµ‹")
                self.btn_camera.setText("ğŸ“¹ åœæ­¢æ‘„åƒå¤´")
                self.btn_camera.setStyleSheet("""
                    QPushButton {
                        background: qlineargradient(x1: 0, y1: 0, x2: 0, y2: 1,
                            stop: 0 #e74c3c, stop: 1 #c0392b);
                        font-size: 13px;
                    }
                """)
                # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
                self.reset_stats()
            else:
                self.console.append("âŒ æ— æ³•å¯åŠ¨æ‘„åƒå¤´")
        else:
            # åœæ­¢æ‘„åƒå¤´
            self.stop_camera()
            self.btn_camera.setText("ğŸ“¹ å®æ—¶æ‘„åƒå¤´")
            self.btn_camera.setStyleSheet("""
                QPushButton {
                    background: qlineargradient(x1: 0, y1: 0, x2: 0, y2: 1,
                        stop: 0 #8e44ad, stop: 1 #6c3483);
                    font-size: 13px;
                }
            """)

    # æ§åˆ¶å›è°ƒå‡½æ•°
    def on_play_clicked(self):
        """å¼€å§‹æ£€æµ‹æŒ‰é’®ç‚¹å‡»"""
        if self.camera_running:
            self.console.append("â–¶ï¸ æ‘„åƒå¤´æ£€æµ‹å·²åœ¨è¿è¡Œ")
        elif self.video_thread and self.video_thread.isRunning():
            self.console.append("â–¶ï¸ è§†é¢‘æ£€æµ‹å·²åœ¨è¿è¡Œ")
        elif self.current_image_path:
            self.console.append("â–¶ï¸ é‡æ–°æ£€æµ‹å½“å‰å›¾åƒ")
            self.detect_image(self.current_image_path)
        else:
            self.console.append("âš ï¸ è¯·å…ˆé€‰æ‹©è¾“å…¥æº")

    def on_stop_clicked(self):
        """åœæ­¢æ£€æµ‹æŒ‰é’®ç‚¹å‡»"""
        self.stop_all()
        self.console.append("â¹ï¸ åœæ­¢æ‰€æœ‰æ£€æµ‹")
        # é‡ç½®ç»Ÿè®¡ä¿¡æ¯
        self.reset_stats()

    def closeEvent(self, event):
        """çª—å£å…³é—­äº‹ä»¶"""
        self.stop_all()
        event.accept()
