# -*- coding: UTF-8 -*-
"""
è‡ªåŠ¨é©¾é©¶ç›®æ ‡æ£€æµ‹ç³»ç»Ÿ - æ‘„åƒå¤´å’Œè§†é¢‘åŠŸèƒ½ç±»
è´Ÿè´£æ‘„åƒå¤´æ“ä½œå’Œè§†é¢‘æ’­æ”¾
"""
import cv2
import numpy as np
from PyQt5.QtCore import QThread, pyqtSignal, Qt
from PyQt5.QtGui import QPixmap, QImage


class AICamera(QThread):
    """çœŸå®æ‘„åƒå¤´çº¿ç¨‹ç±»"""
    sigvideo = pyqtSignal(int, int, int, bytes)

    def __init__(self):
        super(AICamera, self).__init__()
        self.camera = None
        self.isrunning = False
        self.init_camera()

    def init_camera(self):
        """åˆå§‹åŒ–æ‘„åƒå¤´"""
        try:
            # ç¡®ä¿ä¹‹å‰çš„æ‘„åƒå¤´å·²é‡Šæ”¾
            if self.camera and self.camera.isOpened():
                self.camera.release()

            # åˆ›å»ºæ–°çš„æ‘„åƒå¤´å¯¹è±¡
            self.camera = cv2.VideoCapture(0, cv2.CAP_DSHOW)

            # è®¾ç½®æ‘„åƒå¤´å‚æ•°
            if self.camera.isOpened():
                self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                self.camera.set(cv2.CAP_PROP_FPS, 30)
                print("æ‘„åƒå¤´åˆå§‹åŒ–æˆåŠŸ")
            else:
                print("æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥")
        except Exception as e:
            print(f"æ‘„åƒå¤´åˆå§‹åŒ–å¼‚å¸¸: {e}")
            self.camera = None

    def run(self):
        """æ‘„åƒå¤´å·¥ä½œçº¿ç¨‹"""
        self.isrunning = True
        while self.isrunning and self.camera and self.camera.isOpened():
            status, img = self.camera.read()
            if status:
                h, w, c = img.shape
                self.sigvideo.emit(h, w, c, img.tobytes())
            else:
                print("æ‘„åƒå¤´è¯»å–é”™è¯¯")
                break
            QThread.usleep(33000)  # çº¦30fps

        print("æ‘„åƒå¤´çº¿ç¨‹ç»“æŸ")

    def close(self):
        """å…³é—­æ‘„åƒå¤´"""
        print("æ­£åœ¨å…³é—­æ‘„åƒå¤´...")
        self.isrunning = False

        if self.isRunning():
            self.quit()
            self.wait(3000)

        if self.camera and self.camera.isOpened():
            self.camera.release()
            self.camera = None
            print("æ‘„åƒå¤´èµ„æºå·²é‡Šæ”¾")

    def is_camera_available(self):
        """æ£€æŸ¥æ‘„åƒå¤´æ˜¯å¦å¯ç”¨"""
        return self.camera is not None and self.camera.isOpened()


class VideoThread(QThread):
    """è§†é¢‘æ’­æ”¾çº¿ç¨‹"""
    frame_signal = pyqtSignal(QImage)
    finished_signal = pyqtSignal()

    def __init__(self, video_path):
        super().__init__()
        self.video_path = video_path
        self.running = False

    def run(self):
        self.running = True
        cap = cv2.VideoCapture(self.video_path)

        while self.running and cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            h, w, ch = rgb_image.shape
            bytes_per_line = ch * w
            qt_image = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)

            self.frame_signal.emit(qt_image)
            QThread.msleep(33)  # çº¦30fps

        cap.release()
        self.finished_signal.emit()

    def stop(self):
        self.running = False


class CameraVideoHandler:
    """æ‘„åƒå¤´å’Œè§†é¢‘å¤„ç†åŸºç±»"""

    def setup_camera_video(self):
        self.real_camera = None
        self.camera_running = False
        self.video_thread = None
        self.current_image_path = None

    def start_camera(self):
        if self.camera_running:
            self.console.append("ğŸ“¹ æ‘„åƒå¤´å·²åœ¨è¿è¡Œä¸­")
            return True

        self.real_camera = AICamera()

        if self.real_camera.is_camera_available():
            self.real_camera.sigvideo.connect(self.show_real_video)
            self.camera_running = True
            self.real_camera.start()
            self.console.append("ğŸ“¹ æ‘„åƒå¤´å¯åŠ¨æˆåŠŸ")
            return True
        else:
            self.console.append("âŒ æ‘„åƒå¤´ä¸å¯ç”¨")
            self.real_camera = None
            return False

    def stop_camera(self):
        if self.camera_running and self.real_camera:
            self.camera_running = False
            self.real_camera.close()
            self.real_camera.wait()
            self.real_camera = None
            self.console.append("ğŸ“¹ æ‘„åƒå¤´å·²åœæ­¢")

    def show_real_video(self, h, w, c, data):
        """æ˜¾ç¤ºçœŸå®æ‘„åƒå¤´ç”»é¢"""
        try:
            # data æ˜¯ BGRï¼Œéœ€è¦è½¬ RGB
            frame = np.frombuffer(data, dtype=np.uint8).reshape((h, w, c))
            rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            qt_img = QImage(rgb_image.data, w, h, c * w, QImage.Format_RGB888)
            qt_pm = QPixmap.fromImage(qt_img)
            scaled_pixmap = qt_pm.scaled(self.lbl_video.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation)
            self.lbl_video.setPixmap(scaled_pixmap)
        except Exception as e:
            print(f"æ˜¾ç¤ºæ‘„åƒå¤´ç”»é¢é”™è¯¯: {e}")

    def display_image(self, image_path):
        """æ˜¾ç¤ºå›¾åƒï¼ˆæ”¯æŒä¸­æ–‡è·¯å¾„ï¼‰"""
        try:
            image = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)
            if image is None:
                self.console.append(f"âŒ æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶: {image_path}")
                return False

            rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            h, w, ch = rgb_image.shape
            bytes_per_line = ch * w
            qt_image = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format_RGB888)

            pixmap = QPixmap.fromImage(qt_image)
            scaled_pixmap = pixmap.scaled(self.lbl_video.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation)
            self.lbl_video.setPixmap(scaled_pixmap)
            self.console.append("âœ… å›¾åƒæ˜¾ç¤ºæˆåŠŸ")
            return True

        except Exception as e:
            self.console.append(f"âŒ æ˜¾ç¤ºå›¾åƒå¤±è´¥: {str(e)}")
            return False

    def display_video_frame(self, qt_image):
        pixmap = QPixmap.fromImage(qt_image)
        scaled_pixmap = pixmap.scaled(self.lbl_video.size(), Qt.KeepAspectRatio, Qt.SmoothTransformation)
        self.lbl_video.setPixmap(scaled_pixmap)

    def start_video_playback(self, video_path):
        if self.video_thread:
            self.video_thread.stop()
            self.video_thread.wait()

        self.video_thread = VideoThread(video_path)
        self.video_thread.frame_signal.connect(self.display_video_frame)
        self.video_thread.finished_signal.connect(self.on_video_finished)
        self.video_thread.start()
        self.console.append("â–¶ï¸ å¼€å§‹è§†é¢‘æ’­æ”¾")

    def on_video_finished(self):
        self.console.append("â¹ï¸ è§†é¢‘æ’­æ”¾å®Œæˆ")

    def stop_video_playback(self):
        if self.video_thread and self.video_thread.isRunning():
            self.video_thread.stop()
            self.video_thread.wait()
            self.video_thread = None
            self.console.append("â¹ï¸ è§†é¢‘æ’­æ”¾å·²åœæ­¢")

    def stop_all(self):
        if self.camera_running:
            self.stop_camera()
        self.stop_video_playback()
